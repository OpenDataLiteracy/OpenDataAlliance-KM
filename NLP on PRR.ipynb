{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Techniques on Public Records Requests Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "#from sklearn.manifold import TSNE\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from gensim.models import Word2Vec, ldamodel\n",
    "from gensim.corpora import Dictionary\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "\n",
    "\n",
    "# this isn't strictly an import, but it's used globally\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "# change the model for different word vectors\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# and finally, suppress an annoying warning that pandas throws\n",
    "# when using straightforward indexing methods\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and structuring data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the onset of this project, we obtained data extracts from a number of institutions and municipalities of different sizes, with the intention of collating them into one repository for analysis. Upon receipt, there were a handful of things that we realized, which dramatically reduced the kind of analysis that we could perform on the data.\n",
    "\n",
    "1. **Government bodies have different reporting standards for metadata.** I believe this is related to the platform/infrastructure the institution is using to fulfill and manage requests. The fields of interest, as well as the types of data accessible within those fields, are often so distinct that they cannot be combined in a straightforward way. For example, some municipalities have tons of great metadata reporting, especially around the estimated amount of time and actual amount of time that it took to fulfill a request.\n",
    "\n",
    "2. **Inputs are not standardized.** Both people and institutions submit public records requests, which means that there are differing degrees of detail, complexity, and formatting. Some people submit a few words or a case number in their request, while others copy-paste several spreadsheet columns. \n",
    "\n",
    "3. **There is personal identifying information everywhere.** The more I dug into records requests, the more I saw people signing their requests with their name, address, and contact information. It's hard to strip out this information with software, especially because requests ask for information on a particular person or named entity. This is problematic for open data projects, namely because \n",
    "\n",
    "4. **All data are equal, but some data are more equal than others.** This project charts out some methods that can be used across departments that have different numbers of records requests, but there's little we can do (and little inference we can provide) for a department that has but one solitary request.\n",
    "\n",
    "The confluence of all of these factors effectively means that it's hard to look for trends. *Not great.*\n",
    "\n",
    "It's really important to clean and harmonize the data as best we can. As such, we ended up throwing away most of the data that we had and working with a much smaller subset. After importing the data into a pandas dataframe, we kept:\n",
    "\n",
    "- The department name (a string);\n",
    "- Record creation date (a datetime object)\n",
    "- Request summary (a string)\n",
    "\n",
    "It's important to keep the orthography of the names the same, otherwise the information flow in the code here will break."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Metadata Standards\n",
    "Though we are only working with essentially three fields here, I would really like to see the following standard fields as metadata for each request:\n",
    "\n",
    "- Unique Identifier for Record/Case (hash)\n",
    "- Creation Date (datetime object)\n",
    "- Assigned Department (string)\n",
    "- Public Record Request (string; in a perfect world this would be plaintext, to prevent people from copy-pasting in spreadsheets)\n",
    "- Close Date (datetime object)\n",
    "- Attached Objects (myriad of formats)\n",
    "\n",
    "In addition to those fields, these are some extensible fields that would be nice to see:\n",
    "\n",
    "- Estimated Completion Date\n",
    "- Actual Completion Date\n",
    "- Type of Requester (controlled vocabulary; based on user research)\n",
    "\n",
    "Notice that most of these fields are standard to the GovQA or WebQA platforms. If, through the Open Data Alliance, we were to shift to a 'data lake' model for collating and sharing this information, I would also like to see:\n",
    "\n",
    "- Source Name (string; the jurisdiction from which the records request comes from)\n",
    "- Source Type (controlled vocabulary, with possible choices like 'town', 'city', 'state', etc.)\n",
    "- Tags (string; prepopulated based on text mining, and later expanded based on record officer input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 0: Cleaning the Data and Cursory Analysis\n",
    "Let's load things up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section loads an excel sheet.\n",
    "# in an ideal scenario, all of these disparate fiels would live in a database with\n",
    "# a set of standard fields\n",
    "#\n",
    "seadata = pd.read_excel('reformatted.xlsx')\n",
    "olydata = pd.read_excel('StudentPRRLog_06212018_2.xlsx')\n",
    "pordata = pd.read_excel('Port Orchard PRR Data.xls', header=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olympia data entries: 7640 \n",
      "seattle data entries: 23414 \n",
      "port orchard data entries: 246\n"
     ]
    }
   ],
   "source": [
    "# reindex the data above, using only the columns we care about, for olympia\n",
    "oly_trunc = olydata[['Assigned Dept', 'Create Date', 'Public Record Desired']]\n",
    "oly_trunc.columns = ['department_name', 'create_date', 'request_summary']\n",
    "\n",
    "# convert everything in the request_summary column to a spring, so no errors\n",
    "# are thrown when doing natural language processing on data later\n",
    "oly_trunc['request_summary'] = oly_trunc['request_summary'].astype(str)\n",
    "\n",
    "# then drop all of the null values\n",
    "oly_trunc = oly_trunc.dropna().reset_index()\n",
    "del oly_trunc['index']\n",
    "\n",
    "# and similar, but for port orchard\n",
    "droplist = [column for column in pordata.columns if 'Unnamed' in column]\n",
    "pordata.drop(droplist, axis=1, inplace=True)\n",
    "por_trunc = pordata[['Assigned Dept', 'Create Date', 'Public Record Desired']]\n",
    "por_trunc.columns = ['department_name', 'create_date', 'request_summary']\n",
    "por_trunc['request_summary'] = por_trunc['request_summary'].astype(str)\n",
    "por_trunc = por_trunc.dropna().reset_index()\n",
    "del por_trunc['index']\n",
    "\n",
    "# same, but for seattle\n",
    "sea_trunc = seadata[['department_name', 'create_date', 'request_summary']]\n",
    "sea_trunc['request_summary'] = sea_trunc['request_summary'].astype(str)\n",
    "sea_trunc = sea_trunc.dropna().reset_index()\n",
    "del sea_trunc['index']\n",
    "\n",
    "# number of entries in the truncated data blocks\n",
    "print(\"olympia data entries:\", len(oly_trunc),\n",
    "      \"\\nseattle data entries:\", len(sea_trunc),\n",
    "      \"\\nport orchard data entries:\", len(por_trunc))\n",
    "#sum(truncated.request_type_description != truncated.spd_overall_rec_req_description)\n",
    "\n",
    "# later on, consider using NA values as test set for topic modeling. might be overkill?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department_name</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Olympia Police Department</th>\n",
       "      <td>5118</td>\n",
       "      <td>0.66990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Community Planning and Development</th>\n",
       "      <td>1435</td>\n",
       "      <td>0.18783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiple Departments</th>\n",
       "      <td>317</td>\n",
       "      <td>0.04149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>253</td>\n",
       "      <td>0.03312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Administrative Services</th>\n",
       "      <td>183</td>\n",
       "      <td>0.02395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public Works</th>\n",
       "      <td>169</td>\n",
       "      <td>0.02212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human Resources</th>\n",
       "      <td>77</td>\n",
       "      <td>0.01008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legal</th>\n",
       "      <td>43</td>\n",
       "      <td>0.00563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Executive</th>\n",
       "      <td>24</td>\n",
       "      <td>0.00314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks</th>\n",
       "      <td>18</td>\n",
       "      <td>0.00236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Municipal Court</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    department_name      pct\n",
       "Olympia Police Department                      5118  0.66990\n",
       "Community Planning and Development             1435  0.18783\n",
       "Multiple Departments                            317  0.04149\n",
       "Fire                                            253  0.03312\n",
       "Administrative Services                         183  0.02395\n",
       "Public Works                                    169  0.02212\n",
       "Human Resources                                  77  0.01008\n",
       "Legal                                            43  0.00563\n",
       "Executive                                        24  0.00314\n",
       "Parks                                            18  0.00236\n",
       "Municipal Court                                   3  0.00039"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's a list of all of the possible departments we can choose from\n",
    "# as well as the overall percentage that they make up\n",
    "#\n",
    "\n",
    "def dept_count_pct(df):\n",
    "    depts = df['department_name'].value_counts()\n",
    "    deptsdf = pd.DataFrame(depts)\n",
    "    deptsdf['pct'] = (deptsdf['department_name'] / len(df)).round(5)\n",
    "    return deptsdf\n",
    "\n",
    "dept_count_pct(oly_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department_name</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SPD</th>\n",
       "      <td>13789</td>\n",
       "      <td>0.58930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFD</th>\n",
       "      <td>3976</td>\n",
       "      <td>0.16992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Site Administrator</th>\n",
       "      <td>939</td>\n",
       "      <td>0.04013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCI</th>\n",
       "      <td>809</td>\n",
       "      <td>0.03457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAS</th>\n",
       "      <td>740</td>\n",
       "      <td>0.03163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOT</th>\n",
       "      <td>667</td>\n",
       "      <td>0.02851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAW</th>\n",
       "      <td>297</td>\n",
       "      <td>0.01269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEG</th>\n",
       "      <td>294</td>\n",
       "      <td>0.01256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCL</th>\n",
       "      <td>279</td>\n",
       "      <td>0.01192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPU</th>\n",
       "      <td>270</td>\n",
       "      <td>0.01154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOS</th>\n",
       "      <td>224</td>\n",
       "      <td>0.00957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKS</th>\n",
       "      <td>196</td>\n",
       "      <td>0.00838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCR</th>\n",
       "      <td>151</td>\n",
       "      <td>0.00645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHR</th>\n",
       "      <td>119</td>\n",
       "      <td>0.00509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSD</th>\n",
       "      <td>89</td>\n",
       "      <td>0.00380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RET</th>\n",
       "      <td>76</td>\n",
       "      <td>0.00325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCD</th>\n",
       "      <td>69</td>\n",
       "      <td>0.00295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITD</th>\n",
       "      <td>65</td>\n",
       "      <td>0.00278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DON</th>\n",
       "      <td>58</td>\n",
       "      <td>0.00248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEC</th>\n",
       "      <td>44</td>\n",
       "      <td>0.00188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OED</th>\n",
       "      <td>37</td>\n",
       "      <td>0.00158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEN</th>\n",
       "      <td>36</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFH</th>\n",
       "      <td>33</td>\n",
       "      <td>0.00141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>25</td>\n",
       "      <td>0.00107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOE</th>\n",
       "      <td>17</td>\n",
       "      <td>0.00073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSE</th>\n",
       "      <td>17</td>\n",
       "      <td>0.00073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBO</th>\n",
       "      <td>12</td>\n",
       "      <td>0.00051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPL</th>\n",
       "      <td>11</td>\n",
       "      <td>0.00047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OIR</th>\n",
       "      <td>11</td>\n",
       "      <td>0.00047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HXM</th>\n",
       "      <td>9</td>\n",
       "      <td>0.00038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIV</th>\n",
       "      <td>8</td>\n",
       "      <td>0.00034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ART</th>\n",
       "      <td>8</td>\n",
       "      <td>0.00034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMR</th>\n",
       "      <td>7</td>\n",
       "      <td>0.00030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZZZ</th>\n",
       "      <td>7</td>\n",
       "      <td>0.00030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPC</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMC</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPN</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    department_name      pct\n",
       "SPD                           13789  0.58930\n",
       "SFD                            3976  0.16992\n",
       "Site Administrator              939  0.04013\n",
       "SCI                             809  0.03457\n",
       "FAS                             740  0.03163\n",
       "DOT                             667  0.02851\n",
       "LAW                             297  0.01269\n",
       "LEG                             294  0.01256\n",
       "SCL                             279  0.01192\n",
       "SPU                             270  0.01154\n",
       "MOS                             224  0.00957\n",
       "PKS                             196  0.00838\n",
       "OCR                             151  0.00645\n",
       "SHR                             119  0.00509\n",
       "HSD                              89  0.00380\n",
       "RET                              76  0.00325\n",
       "PCD                              69  0.00295\n",
       "ITD                              65  0.00278\n",
       "DON                              58  0.00248\n",
       "EEC                              44  0.00188\n",
       "OED                              37  0.00158\n",
       "CEN                              36  0.00154\n",
       "OFH                              33  0.00141\n",
       "OLS                              25  0.00107\n",
       "DOE                              17  0.00073\n",
       "OSE                              17  0.00073\n",
       "CBO                              12  0.00051\n",
       "SPL                              11  0.00047\n",
       "OIR                              11  0.00047\n",
       "HXM                               9  0.00038\n",
       "CIV                               8  0.00034\n",
       "ART                               8  0.00034\n",
       "IMR                               7  0.00030\n",
       "ZZZ                               7  0.00030\n",
       "CPC                               5  0.00021\n",
       "SMC                               4  0.00017\n",
       "PPN                               1  0.00004"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_count_pct(sea_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department_name</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City Clerk's Office</th>\n",
       "      <td>183</td>\n",
       "      <td>0.75309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Community Development</th>\n",
       "      <td>45</td>\n",
       "      <td>0.18519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public Works Department</th>\n",
       "      <td>14</td>\n",
       "      <td>0.05761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finance Department</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         department_name      pct\n",
       "City Clerk's Office                  183  0.75309\n",
       "Community Development                 45  0.18519\n",
       "Public Works Department               14  0.05761\n",
       "Finance Department                     1  0.00412"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_count_pct(por_trunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is clean and massaged into a form that we can easily work with, we should try to gather some descriptive information about records. Namely, how long are they, on average? We'll measure this in terms of characters, as well as tokens (words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average length (chars)</th>\n",
       "      <th>requests per dept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multiple Departments</th>\n",
       "      <td>436.861199</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Administrative Services</th>\n",
       "      <td>250.065574</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human Resources</th>\n",
       "      <td>297.311688</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legal</th>\n",
       "      <td>170.395349</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>101.988142</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public Works</th>\n",
       "      <td>292.502959</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks</th>\n",
       "      <td>241.333333</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Municipal Court</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Community Planning and Development</th>\n",
       "      <td>177.438328</td>\n",
       "      <td>1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Olympia Police Department</th>\n",
       "      <td>152.511333</td>\n",
       "      <td>5118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Executive</th>\n",
       "      <td>316.291667</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    average length (chars)  requests per dept\n",
       "Multiple Departments                            436.861199                317\n",
       "Administrative Services                         250.065574                183\n",
       "Human Resources                                 297.311688                 77\n",
       "Legal                                           170.395349                 43\n",
       "Fire                                            101.988142                253\n",
       "Public Works                                    292.502959                169\n",
       "Parks                                           241.333333                 18\n",
       "Municipal Court                                  53.000000                  3\n",
       "Community Planning and Development              177.438328               1435\n",
       "Olympia Police Department                       152.511333               5118\n",
       "Executive                                       316.291667                 24"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a helper function that gives us the average length in characters\n",
    "# for each request for each department, and then a higher-level descriptive table\n",
    "# of the same\n",
    "def avglen(df):\n",
    "    # ARGUMENTS: df; a dataframe\n",
    "    # OUTPUTS: a dict; containing column name, average len in chars, number of requests\n",
    "    #\n",
    "    \n",
    "    # get a shortlist of all the names of departments\n",
    "    names = set(df.department_name.values)\n",
    "    \n",
    "    # for \n",
    "    varlist = [df[df.department_name == i]['request_summary'] \n",
    "               for i in names]\n",
    "    \n",
    "    l = [len(i) for i in varlist]\n",
    "    s = []    \n",
    "    for i in varlist:\n",
    "        s.append(sum([len(str(j)) for j in i]))\n",
    "    \n",
    "    avg = [i / j for i,j in zip(s, l)]\n",
    "    \n",
    "    lendict = {n : (v, e ) for n, v, e in zip(names, avg, l)}\n",
    "\n",
    "    return pd.DataFrame.from_dict(lendict, orient='index',\n",
    "                             columns=['average length (chars)', 'requests per dept'])\n",
    "\n",
    "olyagl = avglen(oly_trunc)\n",
    "olyagl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average length (chars)</th>\n",
       "      <th>requests per dept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City Clerk's Office</th>\n",
       "      <td>388.480874</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Community Development</th>\n",
       "      <td>267.333333</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finance Department</th>\n",
       "      <td>192.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public Works Department</th>\n",
       "      <td>284.785714</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         average length (chars)  requests per dept\n",
       "City Clerk's Office                  388.480874                183\n",
       "Community Development                267.333333                 45\n",
       "Finance Department                   192.000000                  1\n",
       "Public Works Department              284.785714                 14"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poragl = avglen(por_trunc)\n",
    "poragl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average length (chars)</th>\n",
       "      <th>requests per dept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SPL</th>\n",
       "      <td>501.454545</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAS</th>\n",
       "      <td>423.393243</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DON</th>\n",
       "      <td>504.879310</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RET</th>\n",
       "      <td>435.828947</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEG</th>\n",
       "      <td>433.112245</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFH</th>\n",
       "      <td>647.030303</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMR</th>\n",
       "      <td>336.428571</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCL</th>\n",
       "      <td>503.150538</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPN</th>\n",
       "      <td>170.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCR</th>\n",
       "      <td>302.913907</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPU</th>\n",
       "      <td>442.125926</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEN</th>\n",
       "      <td>756.638889</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHR</th>\n",
       "      <td>460.436975</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAW</th>\n",
       "      <td>427.646465</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOS</th>\n",
       "      <td>571.803571</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITD</th>\n",
       "      <td>350.169231</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBO</th>\n",
       "      <td>1374.833333</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEC</th>\n",
       "      <td>350.590909</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPD</th>\n",
       "      <td>218.171368</td>\n",
       "      <td>13789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKS</th>\n",
       "      <td>528.994898</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OED</th>\n",
       "      <td>376.756757</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>392.400000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCD</th>\n",
       "      <td>557.231884</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCI</th>\n",
       "      <td>501.159456</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFD</th>\n",
       "      <td>94.916499</td>\n",
       "      <td>3976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HXM</th>\n",
       "      <td>356.666667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIV</th>\n",
       "      <td>251.625000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPC</th>\n",
       "      <td>323.600000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Site Administrator</th>\n",
       "      <td>16.053248</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSE</th>\n",
       "      <td>432.294118</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOT</th>\n",
       "      <td>445.124438</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSD</th>\n",
       "      <td>476.168539</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMC</th>\n",
       "      <td>478.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ART</th>\n",
       "      <td>697.875000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OIR</th>\n",
       "      <td>571.363636</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZZZ</th>\n",
       "      <td>47.285714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOE</th>\n",
       "      <td>506.117647</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    average length (chars)  requests per dept\n",
       "SPL                             501.454545                 11\n",
       "FAS                             423.393243                740\n",
       "DON                             504.879310                 58\n",
       "RET                             435.828947                 76\n",
       "LEG                             433.112245                294\n",
       "OFH                             647.030303                 33\n",
       "IMR                             336.428571                  7\n",
       "SCL                             503.150538                279\n",
       "PPN                             170.000000                  1\n",
       "OCR                             302.913907                151\n",
       "SPU                             442.125926                270\n",
       "CEN                             756.638889                 36\n",
       "SHR                             460.436975                119\n",
       "LAW                             427.646465                297\n",
       "MOS                             571.803571                224\n",
       "ITD                             350.169231                 65\n",
       "CBO                            1374.833333                 12\n",
       "EEC                             350.590909                 44\n",
       "SPD                             218.171368              13789\n",
       "PKS                             528.994898                196\n",
       "OED                             376.756757                 37\n",
       "OLS                             392.400000                 25\n",
       "PCD                             557.231884                 69\n",
       "SCI                             501.159456                809\n",
       "SFD                              94.916499               3976\n",
       "HXM                             356.666667                  9\n",
       "CIV                             251.625000                  8\n",
       "CPC                             323.600000                  5\n",
       "Site Administrator               16.053248                939\n",
       "OSE                             432.294118                 17\n",
       "DOT                             445.124438                667\n",
       "HSD                             476.168539                 89\n",
       "SMC                             478.000000                  4\n",
       "ART                             697.875000                  8\n",
       "OIR                             571.363636                 11\n",
       "ZZZ                              47.285714                  7\n",
       "DOE                             506.117647                 17"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seaagl = avglen(sea_trunc)\n",
    "seaagl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>average length (chars)</th>\n",
       "      <th>requests per dept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">olympia</th>\n",
       "      <th>mean</th>\n",
       "      <td>226.336325</td>\n",
       "      <td>694.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>109.130513</td>\n",
       "      <td>1522.565490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>161.453341</td>\n",
       "      <td>33.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>241.333333</td>\n",
       "      <td>169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>294.907323</td>\n",
       "      <td>285.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>436.861199</td>\n",
       "      <td>5118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">port orchard</th>\n",
       "      <th>mean</th>\n",
       "      <td>283.149980</td>\n",
       "      <td>60.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>80.943927</td>\n",
       "      <td>83.563848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>192.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>248.500000</td>\n",
       "      <td>10.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>276.059524</td>\n",
       "      <td>29.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>310.709504</td>\n",
       "      <td>79.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>388.480874</td>\n",
       "      <td>183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">seattle</th>\n",
       "      <th>mean</th>\n",
       "      <td>439.574102</td>\n",
       "      <td>632.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>226.484746</td>\n",
       "      <td>2322.359605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.053248</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>350.169231</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>435.828947</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>504.879310</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1374.833333</td>\n",
       "      <td>13789.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   average length (chars)  requests per dept\n",
       "olympia      mean              226.336325         694.545455\n",
       "             std               109.130513        1522.565490\n",
       "             min                53.000000           3.000000\n",
       "             25%               161.453341          33.500000\n",
       "             50%               241.333333         169.000000\n",
       "             75%               294.907323         285.000000\n",
       "             max               436.861199        5118.000000\n",
       "port orchard mean              283.149980          60.750000\n",
       "             std                80.943927          83.563848\n",
       "             min               192.000000           1.000000\n",
       "             25%               248.500000          10.750000\n",
       "             50%               276.059524          29.500000\n",
       "             75%               310.709504          79.500000\n",
       "             max               388.480874         183.000000\n",
       "seattle      mean              439.574102         632.405405\n",
       "             std               226.484746        2322.359605\n",
       "             min                16.053248           1.000000\n",
       "             25%               350.169231          11.000000\n",
       "             50%               435.828947          58.000000\n",
       "             75%               504.879310         270.000000\n",
       "             max              1374.833333       13789.000000"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = {'seattle': seaagl.describe()[1:],\n",
    "                'olympia': olyagl.describe()[1:],\n",
    "                'port orchard' : poragl.describe()[1:]}\n",
    "\n",
    "descriptions = pd.concat(desc)\n",
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department_name</th>\n",
       "      <th>request_summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>create_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-10 22:38:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>I am requesting a copy of any allegations of p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-13 19:50:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Regarding Police Officer Nathan Lynch #734, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-16 14:14:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>test request for training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 11:32:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Matrix from staff based on our letter (provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 11:53:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Can you send me the power point on the road cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 12:18:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>Copy of site plans for gas station at 390 SW S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-23 12:31:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>RE: Chris Tibbs' Application to Port Orchard C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-23 12:32:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>I would like to see a copy of the approved dra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-23 20:39:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>1) The mounting location of Officer Nathan Lyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-28 11:41:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Please provide me with each public records req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-07 14:36:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>Please accept this as a request for informatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-08 09:26:00</th>\n",
       "      <td>Finance Department</td>\n",
       "      <td>2016 salary range for the court administrator ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-08 10:48:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>To whom it may concern,  Any of the following ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-08 13:19:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Records for Building A of the old Del's Farm B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-12 11:45:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>I'm looking for construction drawings of Bethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-13 14:32:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>Certificates of Occupancy for Multifamily Hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-13 15:38:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>Building permit records for address 528 Divisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-15 07:14:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>Certificates of Occupancy for Multifamily home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-27 15:11:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Ordinance 017-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-28 13:50:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>This is a test of your new system. I'd like to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-28 16:03:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>July 28, 2016  I request a copy of the settlem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-30 05:12:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>A police report I am party to April/may 2015 A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-02 11:07:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>All code enforcement records on Arnold Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-10 14:08:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>I am looking for any historical building/plann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-15 14:04:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Can I do a \"records request\" for the water/sew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-18 09:57:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Case No. 5Z0735792 Anthony (Tony) N. Benson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-23 10:56:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Copy of Derelict Building Ordinance drafted la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-23 15:14:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>All documents, records, communications (letter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-24 09:26:00</th>\n",
       "      <td>Public Works Department</td>\n",
       "      <td>Water and sewer as-builts for projects I am wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-25 13:19:00</th>\n",
       "      <td>Public Works Department</td>\n",
       "      <td>Parcel No.: 4031-001-001-0002  A copy of the S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27 14:47:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Any and all information regarding cost determi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 07:30:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>I am making a Public Records Request for docum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02 09:08:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>(In a Excel Spreadsheet format) A list of fini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04 19:15:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>Building plans, fuel and heating oil tank reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03 08:00:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Utility records showing payments that were mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-12 13:26:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>All records and drawings for a multi-family de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-13 15:49:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>I am requesting project development permit app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-16 07:39:00</th>\n",
       "      <td>Public Works Department</td>\n",
       "      <td>I am writing to get an update on the current s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-18 09:43:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Any and all documents used, created or maintai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-18 12:42:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>I would like to obtain copies of permits and p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-18 13:16:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>Hi again - In addition to the restaurant space...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20 13:55:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>I am seeking a listing of all individuals who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20 16:21:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Business list or new biz last year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-23 08:00:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Please provide full records of automobile insu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24 10:55:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>Any submitted building plans, permit requests,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24 13:07:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>*I am requesting copies of ALL City records re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30 14:25:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>Any available Community Development Department...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03 08:00:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Electronic communications, Emails and Text mes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10 08:00:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>E-mails between any officer at  Port Orchard P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01 10:03:00</th>\n",
       "      <td>Public Works Department</td>\n",
       "      <td>Contact information for the owner of the Salmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09 12:57:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>Pertaining to the dump trucks on the property</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14 13:50:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Any records relating to this property. Most in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14 13:54:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>RE 206 Mitchell AV Parcel Id 252401-3-036-2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-21 14:33:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>I would like to request a copy of the Conditio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-21 16:04:00</th>\n",
       "      <td>Public Works Department</td>\n",
       "      <td>I would like copies of all proposals submitted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-23 09:49:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>APPROVED PERMITTED BUILDING PLANS FOR \"4759 Ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29 14:14:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>We would like to get all related property site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31 19:15:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>Traci Anne Gregory 01/29/1979 I got a ticket i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-05 16:08:00</th>\n",
       "      <td>City Clerk's Office</td>\n",
       "      <td>I am requesting my training records from my em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 14:42:00</th>\n",
       "      <td>Community Development</td>\n",
       "      <td>Would like to review the project files for McC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             department_name  \\\n",
       "create_date                                    \n",
       "2016-06-10 22:38:00      City Clerk's Office   \n",
       "2016-06-13 19:50:00      City Clerk's Office   \n",
       "2016-06-16 14:14:00      City Clerk's Office   \n",
       "2016-06-17 11:32:00      City Clerk's Office   \n",
       "2016-06-17 11:53:00      City Clerk's Office   \n",
       "2016-06-17 12:18:00    Community Development   \n",
       "2016-06-23 12:31:00      City Clerk's Office   \n",
       "2016-06-23 12:32:00      City Clerk's Office   \n",
       "2016-06-23 20:39:00      City Clerk's Office   \n",
       "2016-06-28 11:41:00      City Clerk's Office   \n",
       "2016-07-07 14:36:00    Community Development   \n",
       "2016-07-08 09:26:00       Finance Department   \n",
       "2016-07-08 10:48:00    Community Development   \n",
       "2016-07-08 13:19:00      City Clerk's Office   \n",
       "2016-07-12 11:45:00    Community Development   \n",
       "2016-07-13 14:32:00    Community Development   \n",
       "2016-07-13 15:38:00    Community Development   \n",
       "2016-07-15 07:14:00    Community Development   \n",
       "2016-07-27 15:11:00      City Clerk's Office   \n",
       "2016-07-28 13:50:00      City Clerk's Office   \n",
       "2016-07-28 16:03:00      City Clerk's Office   \n",
       "2016-07-30 05:12:00      City Clerk's Office   \n",
       "2016-08-02 11:07:00    Community Development   \n",
       "2016-08-10 14:08:00      City Clerk's Office   \n",
       "2016-08-15 14:04:00      City Clerk's Office   \n",
       "2016-08-18 09:57:00      City Clerk's Office   \n",
       "2016-08-23 10:56:00      City Clerk's Office   \n",
       "2016-08-23 15:14:00      City Clerk's Office   \n",
       "2016-08-24 09:26:00  Public Works Department   \n",
       "2016-08-25 13:19:00  Public Works Department   \n",
       "...                                      ...   \n",
       "2018-03-27 14:47:00      City Clerk's Office   \n",
       "2018-04-01 07:30:00      City Clerk's Office   \n",
       "2018-04-02 09:08:00    Community Development   \n",
       "2018-04-04 19:15:00    Community Development   \n",
       "2018-04-03 08:00:00      City Clerk's Office   \n",
       "2018-04-12 13:26:00    Community Development   \n",
       "2018-04-13 15:49:00    Community Development   \n",
       "2018-04-16 07:39:00  Public Works Department   \n",
       "2018-04-18 09:43:00      City Clerk's Office   \n",
       "2018-04-18 12:42:00    Community Development   \n",
       "2018-04-18 13:16:00    Community Development   \n",
       "2018-04-20 13:55:00      City Clerk's Office   \n",
       "2018-04-20 16:21:00      City Clerk's Office   \n",
       "2018-02-23 08:00:00      City Clerk's Office   \n",
       "2018-04-24 10:55:00    Community Development   \n",
       "2018-04-24 13:07:00    Community Development   \n",
       "2018-04-30 14:25:00    Community Development   \n",
       "2018-04-03 08:00:00      City Clerk's Office   \n",
       "2018-04-10 08:00:00      City Clerk's Office   \n",
       "2018-05-01 10:03:00  Public Works Department   \n",
       "2018-05-09 12:57:00    Community Development   \n",
       "2018-05-14 13:50:00      City Clerk's Office   \n",
       "2018-05-14 13:54:00      City Clerk's Office   \n",
       "2018-05-21 14:33:00    Community Development   \n",
       "2018-05-21 16:04:00  Public Works Department   \n",
       "2018-05-23 09:49:00    Community Development   \n",
       "2018-05-29 14:14:00    Community Development   \n",
       "2018-05-31 19:15:00      City Clerk's Office   \n",
       "2018-06-05 16:08:00      City Clerk's Office   \n",
       "2018-06-07 14:42:00    Community Development   \n",
       "\n",
       "                                                       request_summary  \n",
       "create_date                                                             \n",
       "2016-06-10 22:38:00  I am requesting a copy of any allegations of p...  \n",
       "2016-06-13 19:50:00  Regarding Police Officer Nathan Lynch #734, I ...  \n",
       "2016-06-16 14:14:00                          test request for training  \n",
       "2016-06-17 11:32:00  Matrix from staff based on our letter (provide...  \n",
       "2016-06-17 11:53:00  Can you send me the power point on the road cl...  \n",
       "2016-06-17 12:18:00  Copy of site plans for gas station at 390 SW S...  \n",
       "2016-06-23 12:31:00  RE: Chris Tibbs' Application to Port Orchard C...  \n",
       "2016-06-23 12:32:00  I would like to see a copy of the approved dra...  \n",
       "2016-06-23 20:39:00  1) The mounting location of Officer Nathan Lyn...  \n",
       "2016-06-28 11:41:00  Please provide me with each public records req...  \n",
       "2016-07-07 14:36:00  Please accept this as a request for informatio...  \n",
       "2016-07-08 09:26:00  2016 salary range for the court administrator ...  \n",
       "2016-07-08 10:48:00  To whom it may concern,  Any of the following ...  \n",
       "2016-07-08 13:19:00  Records for Building A of the old Del's Farm B...  \n",
       "2016-07-12 11:45:00  I'm looking for construction drawings of Bethe...  \n",
       "2016-07-13 14:32:00  Certificates of Occupancy for Multifamily Hous...  \n",
       "2016-07-13 15:38:00  Building permit records for address 528 Divisi...  \n",
       "2016-07-15 07:14:00  Certificates of Occupancy for Multifamily home...  \n",
       "2016-07-27 15:11:00                                   Ordinance 017-15  \n",
       "2016-07-28 13:50:00  This is a test of your new system. I'd like to...  \n",
       "2016-07-28 16:03:00  July 28, 2016  I request a copy of the settlem...  \n",
       "2016-07-30 05:12:00  A police report I am party to April/may 2015 A...  \n",
       "2016-08-02 11:07:00      All code enforcement records on Arnold Street  \n",
       "2016-08-10 14:08:00  I am looking for any historical building/plann...  \n",
       "2016-08-15 14:04:00  Can I do a \"records request\" for the water/sew...  \n",
       "2016-08-18 09:57:00        Case No. 5Z0735792 Anthony (Tony) N. Benson  \n",
       "2016-08-23 10:56:00  Copy of Derelict Building Ordinance drafted la...  \n",
       "2016-08-23 15:14:00  All documents, records, communications (letter...  \n",
       "2016-08-24 09:26:00  Water and sewer as-builts for projects I am wo...  \n",
       "2016-08-25 13:19:00  Parcel No.: 4031-001-001-0002  A copy of the S...  \n",
       "...                                                                ...  \n",
       "2018-03-27 14:47:00  Any and all information regarding cost determi...  \n",
       "2018-04-01 07:30:00  I am making a Public Records Request for docum...  \n",
       "2018-04-02 09:08:00  (In a Excel Spreadsheet format) A list of fini...  \n",
       "2018-04-04 19:15:00  Building plans, fuel and heating oil tank reco...  \n",
       "2018-04-03 08:00:00  Utility records showing payments that were mad...  \n",
       "2018-04-12 13:26:00  All records and drawings for a multi-family de...  \n",
       "2018-04-13 15:49:00  I am requesting project development permit app...  \n",
       "2018-04-16 07:39:00  I am writing to get an update on the current s...  \n",
       "2018-04-18 09:43:00  Any and all documents used, created or maintai...  \n",
       "2018-04-18 12:42:00  I would like to obtain copies of permits and p...  \n",
       "2018-04-18 13:16:00  Hi again - In addition to the restaurant space...  \n",
       "2018-04-20 13:55:00  I am seeking a listing of all individuals who ...  \n",
       "2018-04-20 16:21:00                Business list or new biz last year.  \n",
       "2018-02-23 08:00:00  Please provide full records of automobile insu...  \n",
       "2018-04-24 10:55:00  Any submitted building plans, permit requests,...  \n",
       "2018-04-24 13:07:00  *I am requesting copies of ALL City records re...  \n",
       "2018-04-30 14:25:00  Any available Community Development Department...  \n",
       "2018-04-03 08:00:00  Electronic communications, Emails and Text mes...  \n",
       "2018-04-10 08:00:00  E-mails between any officer at  Port Orchard P...  \n",
       "2018-05-01 10:03:00  Contact information for the owner of the Salmo...  \n",
       "2018-05-09 12:57:00      Pertaining to the dump trucks on the property  \n",
       "2018-05-14 13:50:00  Any records relating to this property. Most in...  \n",
       "2018-05-14 13:54:00  RE 206 Mitchell AV Parcel Id 252401-3-036-2000...  \n",
       "2018-05-21 14:33:00  I would like to request a copy of the Conditio...  \n",
       "2018-05-21 16:04:00  I would like copies of all proposals submitted...  \n",
       "2018-05-23 09:49:00  APPROVED PERMITTED BUILDING PLANS FOR \"4759 Ru...  \n",
       "2018-05-29 14:14:00  We would like to get all related property site...  \n",
       "2018-05-31 19:15:00  Traci Anne Gregory 01/29/1979 I got a ticket i...  \n",
       "2018-06-05 16:08:00  I am requesting my training records from my em...  \n",
       "2018-06-07 14:42:00  Would like to review the project files for McC...  \n",
       "\n",
       "[243 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bydate = por_trunc.set_index('create_date')\n",
    "\n",
    "bydate\n",
    "por_trunc['summary_token'] = df.apply(lambda row: \n",
    "                                      nltk.word_tokenize(row['sentences']), axis=1)\n",
    "\n",
    "def tokenizedf(df, col):\n",
    "    # takes in a dataframe\n",
    "    # tokenizes the columns in the dataframe\n",
    "    # returns a dataframe with tokenized columns\n",
    "    df = df['tokens']\n",
    "    for row in df[col]:\n",
    "        row = len([nlp_proc(str(row))])\n",
    "        df.\n",
    "    return df\n",
    "\n",
    "test = tokenizedf(bydate, 'request_summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Generating a word cloud for each department"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word clouds, while occasionally superficial, are handy proof-of-concept precursors for more complex linguistic analysis. In order to generate a word cloud, you have to go through most of the same processes (cleaning and splitting data, breaking into constituent parts, etc.) that you do when working on a machine learning pipeline, for example. To that end, here's a wall of code that is used to generate a word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences(df, col):\n",
    "    # ARGUMENTS: df; a pandas dataframe\n",
    "    # OUTPUTS: col, a string; a column of a particular pandas dataframe\n",
    "    #\n",
    "    sents = []\n",
    "    #\n",
    "    # this function takes information out of a table\n",
    "    # and dumps it into a list for further processing\n",
    "    datesplit = re.compile('\\d+|\\D+')\n",
    "    \n",
    "    for row in df[col]:\n",
    "        row = str(row)\n",
    "        # some cleaning happens here as well, to make sure\n",
    "        # that people who use more complex formatting (i.e.\n",
    "        # unicode characters) have their information handled properly\n",
    "        row = row.replace(\"\\t\", \" \")\n",
    "        row = row.replace(\"\\p\", \" \")\n",
    "        row = row.replace('\\uf07f', \" \")\n",
    "        row = row.replace('\\uf0b7', \" \")\n",
    "        row = row.replace('\\uf071', \" \")\n",
    "        sents.append(str(row))\n",
    "    return sents\n",
    "\n",
    "def nlp_proc(data):\n",
    "    # ARGUMENTS: data, either a string or a list\n",
    "    # OUTPUTS: spacy processed text data\n",
    "    #\n",
    "    # this checks to see if the data we are processing is a list\n",
    "    # and if it is, runs the NLP function on the different huge\n",
    "    # strings in the list, returning the list\n",
    "    if type(data) == list:\n",
    "        nlplist = [ nlp(i) for i in data ]\n",
    "        return nlplist\n",
    "    else:\n",
    "        # otherwise it just processes the data; just a backup\n",
    "        return nlp(data)\n",
    "    \n",
    "def filter_noise(token):\n",
    "    # ARGUMENTS: token; a spacy token\n",
    "    # optional: mtl (minimum token length); an int\n",
    "    # optional: cs (custom stop); a boolead\n",
    "    # OUTPUTS: T/F\n",
    "    #\n",
    "    is_noise = False\n",
    "    # this function performs a series of checks to see if \n",
    "    # a token is noise and then returns t/f\n",
    "    # essentially it's a giant switch\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # here's a regular expression for matching dates/times from a string\n",
    "    # spacy doesn't handle that task well\n",
    "    dates = re.compile('\\d{1,2}(?P<sep>[-/])\\d{1,2}(?P=sep)\\d{2,4}')\n",
    "    times = re.compile(r'\\d{1,2}(:\\d{1,2})?(am|pm)?')\n",
    "    \n",
    "    #\n",
    "    # filters stop words\n",
    "    if token.is_stop == True:\n",
    "        is_noise = True\n",
    "    elif token in STOP_WORDS:\n",
    "        is_noise = True\n",
    "        \n",
    "    # measures length of token; default is 3\n",
    "    elif len(token.text) <= 3:\n",
    "        is_noise = True\n",
    "    \n",
    "    # regex filters\n",
    "    elif bool(dates.findall(token.text)) == True:\n",
    "        is_noise = True\n",
    "    elif bool(times.findall(token.text)) == True:\n",
    "        is_noise = True\n",
    "    elif token.text == '-PRON-':\n",
    "        is_noise = True\n",
    "        \n",
    "    # filters things that are/look like numbers\n",
    "    elif token.is_digit == True:\n",
    "        is_noise = True\n",
    "    elif token.is_currency == True:\n",
    "        is_noise = True\n",
    "    elif token.like_num == True:\n",
    "        is_noise = True\n",
    "    # filters web stuff\n",
    "    elif token.like_url == True:\n",
    "        is_noise = True\n",
    "    elif token.like_email == True:\n",
    "        is_noise = True\n",
    "        \n",
    "    # filters punctuation\n",
    "    elif token.is_punct == True:\n",
    "        is_noise = True\n",
    "    elif token.is_left_punct == True:\n",
    "        is_noise = True\n",
    "    elif token.is_right_punct == True:\n",
    "        is_noise = True\n",
    "    elif token.is_bracket == True:\n",
    "        is_noise = True\n",
    "    elif token.is_quote == True:\n",
    "        is_noise = True\n",
    "    elif token.is_space == True:\n",
    "        is_noise = True\n",
    "    elif token.is_alpha == False:\n",
    "        is_noise = True\n",
    "    return is_noise \n",
    "\n",
    "\n",
    "def lem_stop(text, l=True):\n",
    "    # ARGUMENTS: text; a list containing lists, containing spacy tokens\n",
    "    # l; a boolean flag, True by default\n",
    "    # OUTPUTS: a list containing lists, containing lemmas of tokens\n",
    "    #\n",
    "    # empty list, later to become a list of lists\n",
    "    txt = []\n",
    "    #\n",
    "    for sentences in text:\n",
    "        if l == True:\n",
    "            # if the default isn't changed,\n",
    "            # check to see if a word is noise; if not, keep the lemma form in the list\n",
    "            sent = [token.lemma_ for token in sentences if filter_noise(token) == False]\n",
    "        else:\n",
    "            # this alternative mode here is mostly for testing purposes\n",
    "            # and is ignored in the pipeline function\n",
    "            # \n",
    "            # if the defaults are different, just add the complete token\n",
    "            sent = [token for token in sentences if filter_noise(token) == False] \n",
    "        # then append the sentence to the list\n",
    "        txt.append(sent)\n",
    "    return txt\n",
    "\n",
    "# after we transform the text from raw strings into lemmas, we have\n",
    "# to do a secondary layer of filtering to remove additional strings that we\n",
    "# don't really care about, or things that don't contribute in a strong way\n",
    "# to our analysis\n",
    "\n",
    "def filter_lemmas(text, a=False):\n",
    "    # ARGUMENTS: lemma; a unicode string\n",
    "    # OPTIONAL FLAG: a; a boolean, defaults to False\n",
    "    # OUTPUTS: T/F\n",
    "    #\n",
    "    #\n",
    "    is_noise = False\n",
    "    # these are some stop words that occur pretty frequently across docs;\n",
    "    # it might make sense to expand these further\n",
    "    custom_stop_words = ['this', 'that', 'please', 'be', 'file',\n",
    "                         'copy', 'with', 'from', 'like',\n",
    "                         'have', 'other', 'thank', 'and/or',\n",
    "                        'with', '-PRON-']\n",
    "    \n",
    "    other_custom_stops = ['seattle', 'request', 'record', 'document',\n",
    "                         'olympia', 'port', 'orchard']\n",
    "    \n",
    "    for lemma in text:\n",
    "        if lemma in custom_stop_words:\n",
    "            is_noise = True\n",
    "        if a == True:\n",
    "            if lemma in other_custom_stops:\n",
    "                is_noise = True\n",
    "    return is_noise\n",
    "\n",
    "def rec(text, ner=False, vb=False):\n",
    "    # ARGUMENTS: text; a list containing lists, containing spacy tokens\n",
    "    # OUTPUTS: a list containing lists, containing named entities\n",
    "    #\n",
    "    # empty list, later to become a list of lists\n",
    "    txt = []\n",
    "    #\n",
    "    for sentences in text:\n",
    "        if ner == True:\n",
    "            sent = [entity.text for entity in sentences.ents] \n",
    "            # then append the sentence to the list\n",
    "        if vb == True:\n",
    "            sent = [entity.text for entity in sentences if entity.pos_=='VERB'] \n",
    "        txt.append(sent)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df, fl=False):\n",
    "    # a wrapper for all of the functions above\n",
    "    # input: df; a dataframe\n",
    "    # output: export; a list\n",
    "    #\n",
    "    # Flags\n",
    "    #\n",
    "    # running this should take approximately 15min on the full seattle dataset\n",
    "    #\n",
    "    # ensures that we have a 'request' column to work on\n",
    "    # if we don't, this won't work.\n",
    "    \n",
    "    assert 'request_summary' in df.columns\n",
    "    #\n",
    "    #\n",
    "    # this line takes all the text in the request summary column\n",
    "    # and extracts each entry into a list\n",
    "    o = sentences(df, 'request_summary')\n",
    "    \n",
    "    # extract the information, producing a list of sentences (really, a list of tokens)\n",
    "    docs = nlp_proc(o)\n",
    "\n",
    "    # finally, we:\n",
    "    # remove stopwords\n",
    "    # remove punctuation\n",
    "    # lemmatize (reduce to simplest form for purposes of similarity)\n",
    "    texts = lem_stop(docs)\n",
    "\n",
    "\n",
    "    # then we filter out the lemmatized stopwords again,\n",
    "    # but change the flag depending on different degrees of\n",
    "    # filtering\n",
    "    if fl==True:\n",
    "    # if this flag is switched, then filter the additional stopwords\n",
    "        return [i for i in texts if filter_lemmas(i, a=True) == False]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return [i for i in texts if filter_lemmas(i) == False]\n",
    "    \n",
    "\n",
    "def export(df, fn):\n",
    "    # ARGUMENTS: df; a dataframe\n",
    "    # fn; string, a filename\n",
    "    #\n",
    "    # take the file name and append CSV\n",
    "    filename = fn+\"-data.csv\"\n",
    "    # and then write it to the current directory\n",
    "    df.to_csv(filename, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this bit of code runs the above pipeline for each of the different entries in the dataset\n",
    "\n",
    "porpipe = pipeline(por_trunc, fl=True)\n",
    "olypipe = porpipe = pipeline(oly_trunc, fl=True)\n",
    "seapipe = pipeline(sea_trunc, fl=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# and this helper function generates a dataframe of counts for each word,\n",
    "# as well as proportion\n",
    "\n",
    "def countdf(df):\n",
    "    counter = Counter(itertools.chain(*df))\n",
    "    cdf = pd.DataFrame.from_dict(counter, orient='index', columns=['count'])\n",
    "    \n",
    "    # percentage term frequency compared to rest of document\n",
    "    cdf['pct'] = cdf['count'] / sum(cdf['count'])\n",
    "\n",
    "    # normalization to reweight the \"importance\" of a word, invariate to document size\n",
    "    cdf['prp'] = np.log2(cdf['count'])\n",
    "\n",
    "    cdf = cdf.sort_values(by='count', index=True, ascending=False)\n",
    "\n",
    "    return cdf\n",
    "\n",
    "porcount = countdf(porpipe)\n",
    "olycount = countdf(olypipe)\n",
    "seacount = countdf(seapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this bit of code concatenates all of the different counts into a dataframe\n",
    "# and then exports it.\n",
    "\n",
    "citycounts = {'seattle': seacount,\n",
    "              'olympia': olycount,\n",
    "              'port orchard' : porcount}\n",
    "\n",
    "counts = pd.concat(citycounts)\n",
    "\n",
    "# running this will overwrite the existing csv file.\n",
    "export(counts, 'city_counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1.1: Frequency of Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous sections, we had broken up the body of texts into one huge list of words. Something potentially more interesting would be looking for entites (i.e. nouns or noun phrases of note) that appear frequently within a records request.\n",
    "\n",
    "Having this information might suggest items that could be proactively disclosed. For example, if it turns out that one of the most frequently named noun phrases is 'building permits', it might make sense to see which type of building permits are out there, and further if there is a particular class of them that can be easily released to the public.\n",
    "\n",
    "Moreover, if this information is already available, a department recieving these requests might want to redirect users to the place where the information already lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>Nathan Lynch - #</td>\n",
       "      <td>734</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nathan Lynch</td>\n",
       "      <td>734</td>\n",
       "      <td>June 10th, 2016</td>\n",
       "      <td>this day</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matrix</td>\n",
       "      <td>the City Council</td>\n",
       "      <td>the Comprehensive Plan</td>\n",
       "      <td>City Council</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>390</td>\n",
       "      <td>SW Sedgwick Rd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chris Tibbs' Application</td>\n",
       "      <td>Port Orchard City Council</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the Dekalb Pier Improvements Phase 2 project</td>\n",
       "      <td>early this year</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Nathan Lynch</td>\n",
       "      <td>734</td>\n",
       "      <td>2</td>\n",
       "      <td>Nathan Lynch</td>\n",
       "      <td>between the hours of 1200 and 1330 on 6/10/16</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linda Simpson</td>\n",
       "      <td>the City of Port Orchard</td>\n",
       "      <td>January 1, 2015</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the Life Care Center of Port Orchard</td>\n",
       "      <td>2031</td>\n",
       "      <td>Pottery Avenue</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>WA</td>\n",
       "      <td>89366</td>\n",
       "      <td>2005</td>\n",
       "      <td>the Fire Department</td>\n",
       "      <td>UST</td>\n",
       "      <td>AST</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2031</td>\n",
       "      <td>Pottery Avenue</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>Skilled Nursing Facility</td>\n",
       "      <td>Life Care Centers</td>\n",
       "      <td>a Zoning Verification Letter</td>\n",
       "      <td>the Zoning Department</td>\n",
       "      <td>FOIA</td>\n",
       "      <td>Erika Jennings</td>\n",
       "      <td>330</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Del</td>\n",
       "      <td>Farm Building</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bethel Junction Shopping Center</td>\n",
       "      <td>3377</td>\n",
       "      <td>Bethel Rd SE</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>WA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>Port Orchard City</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>528</td>\n",
       "      <td>Division Street</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>Real Prop Tax #</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>1980</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>017-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the July 26, 2016</td>\n",
       "      <td>Chris Henry</td>\n",
       "      <td>Kitsap Sun</td>\n",
       "      <td>360</td>\n",
       "      <td>536-1553</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>July 28, 2016</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>Engley Diversified Inc.</td>\n",
       "      <td>Chris Henry</td>\n",
       "      <td>Kitsap Sun</td>\n",
       "      <td>360</td>\n",
       "      <td>536-1553</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>April/may 2015</td>\n",
       "      <td>2009</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Fit</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>City</td>\n",
       "      <td>720</td>\n",
       "      <td>Prospect Street</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>98366</td>\n",
       "      <td>Parcel #</td>\n",
       "      <td>4650-015-005-0008</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>the last few years</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Anthony</td>\n",
       "      <td>Tony</td>\n",
       "      <td>N. Benson</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>late 2015</td>\n",
       "      <td>2016</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>the High Point Shopping Center</td>\n",
       "      <td>Bethel Road</td>\n",
       "      <td>December of 2007</td>\n",
       "      <td>State No</td>\n",
       "      <td>Disaster No</td>\n",
       "      <td>FEMA</td>\n",
       "      <td>035</td>\n",
       "      <td>January</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Anderson Hill Road SW</td>\n",
       "      <td>SW Old Clifton Road</td>\n",
       "      <td>4-23-1E</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parcel No</td>\n",
       "      <td>4031-001-001-0002</td>\n",
       "      <td>the Stormwater Plan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>215</td>\n",
       "      <td>Thomas Hunter</td>\n",
       "      <td>Steve Dutton</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>RCW</td>\n",
       "      <td>the Kitsap Transit Board</td>\n",
       "      <td>the Kitsap Transit Board</td>\n",
       "      <td>the minutes</td>\n",
       "      <td>the Kitsap Transit Board</td>\n",
       "      <td>the Kitsap Transit Board</td>\n",
       "      <td>the the years of 2015</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>from 2015, 2016, &amp; 2017</td>\n",
       "      <td>#</td>\n",
       "      <td>$$</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>518</td>\n",
       "      <td>536</td>\n",
       "      <td>560</td>\n",
       "      <td>578</td>\n",
       "      <td>Arnold Ave</td>\n",
       "      <td>1822</td>\n",
       "      <td>1942</td>\n",
       "      <td>Lawrence 1880, 1883, 1931</td>\n",
       "      <td>1942</td>\n",
       "      <td>1960</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Altisource Single Family Inc.</td>\n",
       "      <td>222</td>\n",
       "      <td>226</td>\n",
       "      <td>Faragut Avenue</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>the Bethel Heated Self-Storage</td>\n",
       "      <td>Bethel Avenue</td>\n",
       "      <td>Jeff Oldright</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td></td>\n",
       "      <td>ROW</td>\n",
       "      <td> Bethel-Sedgwick Improvements</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>the City of Port Orchard</td>\n",
       "      <td>RCW 40.14.070</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Bay Street Bistro</td>\n",
       "      <td>834 Bay Street</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>98366</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>98366</td>\n",
       "      <td>Ingvil</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Port Orchard Police</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>last year</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>POPD</td>\n",
       "      <td>POPD Department Vehicles</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1935</td>\n",
       "      <td>Lund Avenue</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>98366</td>\n",
       "      <td>1949</td>\n",
       "      <td>Lund Avenue</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>98366</td>\n",
       "      <td>1937</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>minutes</td>\n",
       "      <td>Port Orchard Animal Sign Variance / Appeal Typ...</td>\n",
       "      <td>Assessor Parcel Number</td>\n",
       "      <td>4/24/2018</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Community Development Department</td>\n",
       "      <td>Public Works Department</td>\n",
       "      <td>1440 - 1500</td>\n",
       "      <td>Southeast Bethel Valley Lane</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>WA</td>\n",
       "      <td>98366</td>\n",
       "      <td>Historical Parcel</td>\n",
       "      <td>022301</td>\n",
       "      <td>Current Parcels</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Signal Messenger</td>\n",
       "      <td>WhatsApp</td>\n",
       "      <td>Wire</td>\n",
       "      <td>Wickr</td>\n",
       "      <td>Telegram</td>\n",
       "      <td>iMessage</td>\n",
       "      <td>Facebook Chat</td>\n",
       "      <td>Slack, Glip</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Port Orchard Police Department</td>\n",
       "      <td>Kitsap County</td>\n",
       "      <td>18-000846</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>206</td>\n",
       "      <td>Mitchell AV Parcel</td>\n",
       "      <td>252401-3-036-2000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>the Conditional Use Permit No</td>\n",
       "      <td>07-47968</td>\n",
       "      <td>10/3/2008</td>\n",
       "      <td>Parcel No. 082301-2-001-2005</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>RFQ</td>\n",
       "      <td>CITY OF PORT ORCHARD NOTICE TO CONSULTANTS MAR...</td>\n",
       "      <td>DESIGN</td>\n",
       "      <td>CACM</td>\n",
       "      <td>Dec. 15th</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jan. 12th, 2018</td>\n",
       "      <td></td>\n",
       "      <td>Melissa Anderson</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>4759</td>\n",
       "      <td>Rutherford Cir</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>WA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>the City of Port Orchard Community Development</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Traci Anne Gregory</td>\n",
       "      <td>Port Orchard</td>\n",
       "      <td>some time ago</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>McCormick Woods Phase III</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows  64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 0   \\\n",
       "0                                      Port Orchard   \n",
       "1                                      Nathan Lynch   \n",
       "2                                              None   \n",
       "3                                            Matrix   \n",
       "4                                              None   \n",
       "5                                               390   \n",
       "6                          Chris Tibbs' Application   \n",
       "7      the Dekalb Pier Improvements Phase 2 project   \n",
       "8                                                 1   \n",
       "9                                     Linda Simpson   \n",
       "10             the Life Care Center of Port Orchard   \n",
       "11                                             2016   \n",
       "12                                             2031   \n",
       "13                                              Del   \n",
       "14                  Bethel Junction Shopping Center   \n",
       "15                                               11   \n",
       "16                                              528   \n",
       "17                                                5   \n",
       "18                                           017-15   \n",
       "19                                the July 26, 2016   \n",
       "20                                    July 28, 2016   \n",
       "21                                   April/may 2015   \n",
       "22                                             None   \n",
       "23                                             City   \n",
       "24                               the last few years   \n",
       "25                                          Anthony   \n",
       "26                                        late 2015   \n",
       "27                   the High Point Shopping Center   \n",
       "28                            Anderson Hill Road SW   \n",
       "29                                        Parcel No   \n",
       "..                                              ...   \n",
       "216                                             215   \n",
       "217                                             RCW   \n",
       "218                         from 2015, 2016, & 2017   \n",
       "219                                             518   \n",
       "220                   Altisource Single Family Inc.   \n",
       "221                                            None   \n",
       "222                  the Bethel Heated Self-Storage   \n",
       "223                                                   \n",
       "224                        the City of Port Orchard   \n",
       "225                               Bay Street Bistro   \n",
       "226                                    Port Orchard   \n",
       "227                             Port Orchard Police   \n",
       "228                                       last year   \n",
       "229                                            POPD   \n",
       "230                                            1935   \n",
       "231                                         minutes   \n",
       "232                Community Development Department   \n",
       "233                                Signal Messenger   \n",
       "234                  Port Orchard Police Department   \n",
       "235                                            None   \n",
       "236                                            None   \n",
       "237                                            None   \n",
       "238                                             206   \n",
       "239                   the Conditional Use Permit No   \n",
       "240                                             RFQ   \n",
       "241                                            4759   \n",
       "242  the City of Port Orchard Community Development   \n",
       "243                              Traci Anne Gregory   \n",
       "244                                            None   \n",
       "245                       McCormick Woods Phase III   \n",
       "\n",
       "                                                    1   \\\n",
       "0                                     Nathan Lynch - #   \n",
       "1                                                  734   \n",
       "2                                                 None   \n",
       "3                                     the City Council   \n",
       "4                                                 None   \n",
       "5                                       SW Sedgwick Rd   \n",
       "6                            Port Orchard City Council   \n",
       "7                                      early this year   \n",
       "8                                         Nathan Lynch   \n",
       "9                             the City of Port Orchard   \n",
       "10                                                2031   \n",
       "11                                                None   \n",
       "12                                      Pottery Avenue   \n",
       "13                                       Farm Building   \n",
       "14                                                3377   \n",
       "15                                   Port Orchard City   \n",
       "16                                     Division Street   \n",
       "17                                                1980   \n",
       "18                                                None   \n",
       "19                                         Chris Henry   \n",
       "20                                        Port Orchard   \n",
       "21                                                2009   \n",
       "22                                                None   \n",
       "23                                                 720   \n",
       "24                                                None   \n",
       "25                                                Tony   \n",
       "26                                                2016   \n",
       "27                                         Bethel Road   \n",
       "28                                 SW Old Clifton Road   \n",
       "29                                   4031-001-001-0002   \n",
       "..                                                 ...   \n",
       "216                                      Thomas Hunter   \n",
       "217                           the Kitsap Transit Board   \n",
       "218                                                  #   \n",
       "219                                                536   \n",
       "220                                                222   \n",
       "221                                               None   \n",
       "222                                      Bethel Avenue   \n",
       "223                                                ROW   \n",
       "224                                      RCW 40.14.070   \n",
       "225                                     834 Bay Street   \n",
       "226                                              98366   \n",
       "227                                               None   \n",
       "228                                               None   \n",
       "229                           POPD Department Vehicles   \n",
       "230                                        Lund Avenue   \n",
       "231  Port Orchard Animal Sign Variance / Appeal Typ...   \n",
       "232                            Public Works Department   \n",
       "233                                           WhatsApp   \n",
       "234                                      Kitsap County   \n",
       "235                                               None   \n",
       "236                                               None   \n",
       "237                                               None   \n",
       "238                                 Mitchell AV Parcel   \n",
       "239                                           07-47968   \n",
       "240  CITY OF PORT ORCHARD NOTICE TO CONSULTANTS MAR...   \n",
       "241                                     Rutherford Cir   \n",
       "242                                               None   \n",
       "243                                       Port Orchard   \n",
       "244                                               None   \n",
       "245                                               None   \n",
       "\n",
       "                                 2                             3   \\\n",
       "0                               734                          None   \n",
       "1                   June 10th, 2016                      this day   \n",
       "2                              None                          None   \n",
       "3            the Comprehensive Plan                  City Council   \n",
       "4                              None                          None   \n",
       "5                              None                          None   \n",
       "6                              None                          None   \n",
       "7                             Bruce                          None   \n",
       "8                               734                             2   \n",
       "9                   January 1, 2015                          None   \n",
       "10                   Pottery Avenue                  Port Orchard   \n",
       "11                             None                          None   \n",
       "12                     Port Orchard      Skilled Nursing Facility   \n",
       "13                             None                          None   \n",
       "14                     Bethel Rd SE                  Port Orchard   \n",
       "15                             2000                          None   \n",
       "16                     Port Orchard               Real Prop Tax #   \n",
       "17                             None                          None   \n",
       "18                             None                          None   \n",
       "19                       Kitsap Sun                           360   \n",
       "20          Engley Diversified Inc.                   Chris Henry   \n",
       "21                            Honda                           Fit   \n",
       "22                             None                          None   \n",
       "23                  Prospect Street                  Port Orchard   \n",
       "24                             None                          None   \n",
       "25                        N. Benson                          None   \n",
       "26                                                           None   \n",
       "27                 December of 2007                      State No   \n",
       "28                          4-23-1E                          None   \n",
       "29              the Stormwater Plan                          None   \n",
       "..                              ...                           ...   \n",
       "216                    Steve Dutton                          None   \n",
       "217        the Kitsap Transit Board                   the minutes   \n",
       "218                              $$                          None   \n",
       "219                             560                           578   \n",
       "220                             226                Faragut Avenue   \n",
       "221                            None                          None   \n",
       "222                   Jeff Oldright                          None   \n",
       "223   Bethel-Sedgwick Improvements                                 \n",
       "224                            None                          None   \n",
       "225                    Port Orchard                         98366   \n",
       "226                          Ingvil                          None   \n",
       "227                            None                          None   \n",
       "228                            None                          None   \n",
       "229                            None                          None   \n",
       "230                    Port Orchard                         98366   \n",
       "231          Assessor Parcel Number                     4/24/2018   \n",
       "232                     1440 - 1500  Southeast Bethel Valley Lane   \n",
       "233                            Wire                         Wickr   \n",
       "234                       18-000846                          None   \n",
       "235                            None                          None   \n",
       "236                            None                          None   \n",
       "237                            None                          None   \n",
       "238               252401-3-036-2000                          None   \n",
       "239                       10/3/2008  Parcel No. 082301-2-001-2005   \n",
       "240                          DESIGN                          CACM   \n",
       "241                    Port Orchard                            WA   \n",
       "242                            None                          None   \n",
       "243                   some time ago                                 \n",
       "244                            None                          None   \n",
       "245                            None                          None   \n",
       "\n",
       "                           4                                              5   \\\n",
       "0                        None                                           None   \n",
       "1                        None                                           None   \n",
       "2                        None                                           None   \n",
       "3                        None                                           None   \n",
       "4                        None                                           None   \n",
       "5                        None                                           None   \n",
       "6                        None                                           None   \n",
       "7                        None                                           None   \n",
       "8                Nathan Lynch  between the hours of 1200 and 1330 on 6/10/16   \n",
       "9                        None                                           None   \n",
       "10                         WA                                          89366   \n",
       "11                       None                                           None   \n",
       "12          Life Care Centers                   a Zoning Verification Letter   \n",
       "13                       None                                           None   \n",
       "14                         WA                                           None   \n",
       "15                       None                                           None   \n",
       "16                       None                                           None   \n",
       "17                       None                                           None   \n",
       "18                       None                                           None   \n",
       "19                   536-1553                                           None   \n",
       "20                 Kitsap Sun                                            360   \n",
       "21                       None                                           None   \n",
       "22                       None                                           None   \n",
       "23                      98366                                       Parcel #   \n",
       "24                       None                                           None   \n",
       "25                       None                                           None   \n",
       "26                       None                                           None   \n",
       "27                Disaster No                                           FEMA   \n",
       "28                       None                                           None   \n",
       "29                       None                                           None   \n",
       "..                        ...                                            ...   \n",
       "216                      None                                           None   \n",
       "217  the Kitsap Transit Board                       the Kitsap Transit Board   \n",
       "218                      None                                           None   \n",
       "219                Arnold Ave                                           1822   \n",
       "220                      None                                           None   \n",
       "221                      None                                           None   \n",
       "222                      None                                           None   \n",
       "223                                                                     None   \n",
       "224                      None                                           None   \n",
       "225                      None                                           None   \n",
       "226                      None                                           None   \n",
       "227                      None                                           None   \n",
       "228                      None                                           None   \n",
       "229                      None                                           None   \n",
       "230                      1949                                    Lund Avenue   \n",
       "231                      None                                           None   \n",
       "232              Port Orchard                                             WA   \n",
       "233                  Telegram                                       iMessage   \n",
       "234                      None                                           None   \n",
       "235                      None                                           None   \n",
       "236                      None                                           None   \n",
       "237                      None                                           None   \n",
       "238                      None                                           None   \n",
       "239                      None                                           None   \n",
       "240                 Dec. 15th                                           2017   \n",
       "241                      None                                           None   \n",
       "242                      None                                           None   \n",
       "243                      None                                           None   \n",
       "244                      None                                           None   \n",
       "245                      None                                           None   \n",
       "\n",
       "                        6                          7                 8   \\\n",
       "0                     None                       None              None   \n",
       "1                     None                       None              None   \n",
       "2                     None                       None              None   \n",
       "3                     None                       None              None   \n",
       "4                     None                       None              None   \n",
       "5                     None                       None              None   \n",
       "6                     None                       None              None   \n",
       "7                     None                       None              None   \n",
       "8                     None                       None              None   \n",
       "9                     None                       None              None   \n",
       "10                    2005        the Fire Department               UST   \n",
       "11                    None                       None              None   \n",
       "12   the Zoning Department                       FOIA    Erika Jennings   \n",
       "13                    None                       None              None   \n",
       "14                    None                       None              None   \n",
       "15                    None                       None              None   \n",
       "16                    None                       None              None   \n",
       "17                    None                       None              None   \n",
       "18                    None                       None              None   \n",
       "19                    None                       None              None   \n",
       "20                536-1553                       None              None   \n",
       "21                    None                       None              None   \n",
       "22                    None                       None              None   \n",
       "23       4650-015-005-0008                       None              None   \n",
       "24                    None                       None              None   \n",
       "25                    None                       None              None   \n",
       "26                    None                       None              None   \n",
       "27                     035                    January              None   \n",
       "28                    None                       None              None   \n",
       "29                    None                       None              None   \n",
       "..                     ...                        ...               ...   \n",
       "216                   None                       None              None   \n",
       "217  the the years of 2015                       None              None   \n",
       "218                   None                       None              None   \n",
       "219                   1942  Lawrence 1880, 1883, 1931              1942   \n",
       "220                   None                       None              None   \n",
       "221                   None                       None              None   \n",
       "222                   None                       None              None   \n",
       "223                   None                       None              None   \n",
       "224                   None                       None              None   \n",
       "225                   None                       None              None   \n",
       "226                   None                       None              None   \n",
       "227                   None                       None              None   \n",
       "228                   None                       None              None   \n",
       "229                   None                       None              None   \n",
       "230           Port Orchard                      98366              1937   \n",
       "231                   None                       None              None   \n",
       "232                  98366          Historical Parcel            022301   \n",
       "233          Facebook Chat                Slack, Glip          Facebook   \n",
       "234                   None                       None              None   \n",
       "235                   None                       None              None   \n",
       "236                   None                       None              None   \n",
       "237                   None                       None              None   \n",
       "238                   None                       None              None   \n",
       "239                   None                       None              None   \n",
       "240        Jan. 12th, 2018                             Melissa Anderson   \n",
       "241                   None                       None              None   \n",
       "242                   None                       None              None   \n",
       "243                   None                       None              None   \n",
       "244                   None                       None              None   \n",
       "245                   None                       None              None   \n",
       "\n",
       "                    9   ...     54    55    56    57    58    59    60    61  \\\n",
       "0                 None  ...   None  None  None  None  None  None  None  None   \n",
       "1                 None  ...   None  None  None  None  None  None  None  None   \n",
       "2                 None  ...   None  None  None  None  None  None  None  None   \n",
       "3                 None  ...   None  None  None  None  None  None  None  None   \n",
       "4                 None  ...   None  None  None  None  None  None  None  None   \n",
       "5                 None  ...   None  None  None  None  None  None  None  None   \n",
       "6                 None  ...   None  None  None  None  None  None  None  None   \n",
       "7                 None  ...   None  None  None  None  None  None  None  None   \n",
       "8                 None  ...   None  None  None  None  None  None  None  None   \n",
       "9                 None  ...   None  None  None  None  None  None  None  None   \n",
       "10                 AST  ...   None  None  None  None  None  None  None  None   \n",
       "11                None  ...   None  None  None  None  None  None  None  None   \n",
       "12                 330  ...   None  None  None  None  None  None  None  None   \n",
       "13                None  ...   None  None  None  None  None  None  None  None   \n",
       "14                None  ...   None  None  None  None  None  None  None  None   \n",
       "15                None  ...   None  None  None  None  None  None  None  None   \n",
       "16                None  ...   None  None  None  None  None  None  None  None   \n",
       "17                None  ...   None  None  None  None  None  None  None  None   \n",
       "18                None  ...   None  None  None  None  None  None  None  None   \n",
       "19                None  ...   None  None  None  None  None  None  None  None   \n",
       "20                None  ...   None  None  None  None  None  None  None  None   \n",
       "21                None  ...   None  None  None  None  None  None  None  None   \n",
       "22                None  ...   None  None  None  None  None  None  None  None   \n",
       "23                None  ...   None  None  None  None  None  None  None  None   \n",
       "24                None  ...   None  None  None  None  None  None  None  None   \n",
       "25                None  ...   None  None  None  None  None  None  None  None   \n",
       "26                None  ...   None  None  None  None  None  None  None  None   \n",
       "27                None  ...   None  None  None  None  None  None  None  None   \n",
       "28                None  ...   None  None  None  None  None  None  None  None   \n",
       "29                None  ...   None  None  None  None  None  None  None  None   \n",
       "..                 ...  ...    ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "216               None  ...   None  None  None  None  None  None  None  None   \n",
       "217               None  ...   None  None  None  None  None  None  None  None   \n",
       "218               None  ...   None  None  None  None  None  None  None  None   \n",
       "219               1960  ...   None  None  None  None  None  None  None  None   \n",
       "220               None  ...   None  None  None  None  None  None  None  None   \n",
       "221               None  ...   None  None  None  None  None  None  None  None   \n",
       "222               None  ...   None  None  None  None  None  None  None  None   \n",
       "223               None  ...   None  None  None  None  None  None  None  None   \n",
       "224               None  ...   None  None  None  None  None  None  None  None   \n",
       "225               None  ...   None  None  None  None  None  None  None  None   \n",
       "226               None  ...   None  None  None  None  None  None  None  None   \n",
       "227               None  ...   None  None  None  None  None  None  None  None   \n",
       "228               None  ...   None  None  None  None  None  None  None  None   \n",
       "229               None  ...   None  None  None  None  None  None  None  None   \n",
       "230               None  ...   None  None  None  None  None  None  None  None   \n",
       "231               None  ...   None  None  None  None  None  None  None  None   \n",
       "232    Current Parcels  ...   None  None  None  None  None  None  None  None   \n",
       "233            Twitter  ...   None  None  None  None  None  None  None  None   \n",
       "234               None  ...   None  None  None  None  None  None  None  None   \n",
       "235               None  ...   None  None  None  None  None  None  None  None   \n",
       "236               None  ...   None  None  None  None  None  None  None  None   \n",
       "237               None  ...   None  None  None  None  None  None  None  None   \n",
       "238               None  ...   None  None  None  None  None  None  None  None   \n",
       "239               None  ...   None  None  None  None  None  None  None  None   \n",
       "240               None  ...   None  None  None  None  None  None  None  None   \n",
       "241               None  ...   None  None  None  None  None  None  None  None   \n",
       "242               None  ...   None  None  None  None  None  None  None  None   \n",
       "243               None  ...   None  None  None  None  None  None  None  None   \n",
       "244               None  ...   None  None  None  None  None  None  None  None   \n",
       "245               None  ...   None  None  None  None  None  None  None  None   \n",
       "\n",
       "       62    63  \n",
       "0    None  None  \n",
       "1    None  None  \n",
       "2    None  None  \n",
       "3    None  None  \n",
       "4    None  None  \n",
       "5    None  None  \n",
       "6    None  None  \n",
       "7    None  None  \n",
       "8    None  None  \n",
       "9    None  None  \n",
       "10   None  None  \n",
       "11   None  None  \n",
       "12   None  None  \n",
       "13   None  None  \n",
       "14   None  None  \n",
       "15   None  None  \n",
       "16   None  None  \n",
       "17   None  None  \n",
       "18   None  None  \n",
       "19   None  None  \n",
       "20   None  None  \n",
       "21   None  None  \n",
       "22   None  None  \n",
       "23   None  None  \n",
       "24   None  None  \n",
       "25   None  None  \n",
       "26   None  None  \n",
       "27   None  None  \n",
       "28   None  None  \n",
       "29   None  None  \n",
       "..    ...   ...  \n",
       "216  None  None  \n",
       "217  None  None  \n",
       "218  None  None  \n",
       "219  None  None  \n",
       "220  None  None  \n",
       "221  None  None  \n",
       "222  None  None  \n",
       "223  None  None  \n",
       "224  None  None  \n",
       "225  None  None  \n",
       "226  None  None  \n",
       "227  None  None  \n",
       "228  None  None  \n",
       "229  None  None  \n",
       "230  None  None  \n",
       "231  None  None  \n",
       "232  None  None  \n",
       "233  None  None  \n",
       "234  None  None  \n",
       "235  None  None  \n",
       "236  None  None  \n",
       "237  None  None  \n",
       "238  None  None  \n",
       "239  None  None  \n",
       "240  None  None  \n",
       "241  None  None  \n",
       "242  None  None  \n",
       "243  None  None  \n",
       "244  None  None  \n",
       "245  None  None  \n",
       "\n",
       "[246 rows x 64 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_ents(text):\n",
    "    # ARGUMENTS: lemma; a unicode string\n",
    "    # OUTPUTS: T/F\n",
    "    #\n",
    "    is_noise = False\n",
    "    # these are some stop words that occur pretty frequently across docs;\n",
    "    # it might make sense to expand these further\n",
    "    remove_ents = [' ', '', str([])]\n",
    "    for ent in text:\n",
    "        if ent in remove_ents:\n",
    "            is_noise = True\n",
    "    return is_noise\n",
    "\n",
    "ents = rec(docs, ner=True)\n",
    "collapse_ents = [' '.join(e) for e in ents if filter_ents(e) == False]\n",
    "\n",
    "edf = pd.DataFrame(ents)#, columns=['string'])\n",
    "#ecounter = pd.DataFrame(edf.value_counts())\n",
    "#collapse = [str(e) for e in ents for i in e]\n",
    "#ecounter\n",
    "#edf.values.reshape(edf.shape, 1)\n",
    "edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Clustering using LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Latent Dirichlet Allocation (LDA)?\n",
    "Latent dirichlet allocation (LDA) is a tool for finding implicit relationships in a large body of text. The algorithm produces topics, which essentially are groupings of words that we--statistically speaking--expect to have some degree of association (represented through co-occurrence within a document). As such, topics are not explicitly related through semantics or knowledge content--it is through later inference that we understand the emergent higher-level categories.\n",
    "\n",
    "For example, consider a body of text that contains keywords like 'China', 'black', 'white', 'spotted', 'Croatia', 'cute', and 'bamboo'. It could be the case that a subset of these words are explicitly (and exclusively) related to a particular category, while others occur within each category with about the same frequency distribution.\n",
    "\n",
    "Using LDA, we are able to categorize all of these words into groups that make sense. The computer groups 'China', 'bamboo', 'black', 'white', and 'cute' together, and our human inference suggests *'panda'*. In contrast, if we see 'Croatia', 'spotted', 'black', 'white', and 'cute', in the computer output, we think *'dalmatian'*. It's okay that the different topics overlap--as in human languages, semantic meaning is often distributed across different words.\n",
    "\n",
    "More complicated algorithms can be used to assign actual labels to topic categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary for port orchard\n",
    "id2word = Dictionary(porpipe)\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(txt) for txt in texts]\n",
    "\n",
    "passes = 50\n",
    "rs = 7\n",
    "# how do we decide on a good number of topics\n",
    "num_topics = 10\n",
    "\n",
    "lda_40 = ldamodel.LdaModel(corpus, \n",
    "                        num_topics=num_topics, \n",
    "                        id2word = id2word, \n",
    "                        passes=passes, \n",
    "                        random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(lda_40.print_topics())\n",
    "\n",
    "# subtract the sum of all of the topic coefficients from 1 in order to get the most viable topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Cosine Similarity Using Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Word2Vec?\n",
    "\n",
    "Word2vec is an algorithmic system used to produce word embeddings, which may need some explanation or unpacking. Think back to the LDA section of this document. The computer produced a clustering of words, and we used our associative human creativity to establish patterns and relationships between them. What if it were possible to determine the similarity or semantic relationship between words programmatically?\n",
    "\n",
    "Word2vec achieves this by taking a large body of text and representing it as a vector space. Each word contained within that vector space is encoded as a vector, comprised of a 1 where the word is and 0's everywhere else). There is a hidden filter layer which compresses the size of this vector while minimizing information loss, as smaller vectors are less computationally complex to compare. Finally, the word vectors are all positioned in the vector space relative to each other, with more similar words clustered together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite abstract, so let's try out an example. Assume that we have the sentences \"Bananas and apples are delicious,\" and \"Durian and jackfruit are unpleasant.\" We can represent each of these as a list of words:\n",
    "\n",
    "`document1 = ['Bananas', 'and', 'apples', 'are', 'delicious', '.']`\n",
    "\n",
    "`document2 = ['Durian', 'and', 'jackfruit', 'are', 'unpleasant', '.']`\n",
    "\n",
    "And then as a vector space, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bananas       [1, 0]\n",
       "durian        [0, 1]\n",
       "and           [1, 1]\n",
       "apples        [1, 0]\n",
       "jackfruit     [0, 1]\n",
       "are           [1, 1]\n",
       "delicious     [1, 0]\n",
       "unpleasant    [0, 1]\n",
       ".             [1, 1]\n",
       "dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'bananas': [1, 0], 'durian': [0, 1], 'and': [1, 1],\n",
    "     'apples': [1, 0], 'jackfruit': [0, 1], 'are': [1, 1],\n",
    "    'delicious': [1, 0], 'unpleasant': [0, 1], '.': [1, 1]}\n",
    "\n",
    "s  = pd.Series(d,index=d.keys())\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have produced an excellent vector space here, we can make the vector space more sparse and easier to work with by dropping items that do not have semantic relevance. That includes words like 'and' and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bananas       [1, 0]\n",
       "durian        [0, 1]\n",
       "apples        [1, 0]\n",
       "jackfruit     [0, 1]\n",
       "delicious     [1, 0]\n",
       "unpleasant    [0, 1]\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = {'bananas': [1, 0], 'durian': [0, 1],\n",
    "     'apples': [1, 0], 'jackfruit': [0, 1],\n",
    "    'delicious': [1, 0], 'unpleasant': [0, 1]}\n",
    "\n",
    "t  = pd.Series(e,index=e.keys())\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is our vector *space*. A *word vector* is the representation of the word with regard to the entire vecor space. The following word vectors are represented like this, relative to their presence within the vector space, and the documents in which they appear:\n",
    "\n",
    "`bananas = [1, 0, 0, 0, 0, 0]`\n",
    "\n",
    "`durian = [0, 1, 0, 0, 0, 0]`\n",
    "\n",
    "`delicious = [0, 0, 0, 0, 1, 0]`\n",
    "\n",
    "`unpleasant = [0, 0, 0, 0, 0, 1]`\n",
    "\n",
    "This is a simplistic picture of how a word vector operates. There is little insight that we can derive from this, other than comparing direct equivalence of vectors. But things become interesting when there is a significantly large corpus of documents, with different uses and contexts for words.\n",
    "\n",
    "Word2vec takes word vectors for every word that appears in a corpus (as above) and represents their contexts as a series of weights. Think of it like creating a dictionary, where each definition is composed of a little piece of every other definition, but to varying degrees. Because each definition of a word is created relationally, it is possible to capture conceptual or syntactic meaning an a really robust, fascinating (almost surprising) way.\n",
    "\n",
    "Supposing we had more data (a huge set of other documents), the previous word vectors might be transformed to contain all of the \"definitions\" of the other words within the dataset:\n",
    "\n",
    "`bananas = [0.89123, 0.66545, 0.19842, 0.11901, 0.09113, 0.07221]`\n",
    "\n",
    "`durian = [0.12311, 0.71834, 0.22142, 0.13452, 0.08721, 0.067881]`\n",
    "\n",
    "`delicious = [0.13317, 0.17004, 0.21891, 0.66311, 0.88313, 0.70019]`\n",
    "\n",
    "`unpleasant = [0.14141, 0.16167, 0.22212, 0.57719, 0.77311, 0.87123]`\n",
    "\n",
    "Other algorithms can be used to reduce the dimensionality of the vector space, such that each of these vectors can be plotted in 2D space. For a naive explanation of how this works, check out the bolded components of each of these vectors:\n",
    "\n",
    "`bananas = [`**0.89123`, `0.66545**`, 0.19842, 0.11901, 0.09113, 0.07221]`\n",
    "\n",
    "`durian = [`**0.71311`, `0.86834**`, 0.22142, 0.13452, 0.08721, 0.067881]`\n",
    "\n",
    "`delicious = [0.13317, 0.17004, 0.21891, 0.38311, `**0.88313`, `0.70019**`]`\n",
    "\n",
    "`unpleasant = [0.14141, 0.16167, 0.22212, 0.57719, `**0.77311`, `0.87123**`]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "#\n",
    "# error messages of note, in case further problems arise:\n",
    "# https://stackoverflow.com/questions/33989826/python-gensim-runtimeerror-you-must-first-build-vocabulary-before-training-th/33991111\n",
    "# \n",
    "\n",
    "# the number of dimensions of generated vectors. this is a good number to\n",
    "# play around with. some people suggest square-root length of vocabulary\n",
    "# conceptually this might map onto principle components, or number of topics\n",
    "size = 50\n",
    "\n",
    "# terms that occur less than min_count number \n",
    "# of times are ignored in calculations\n",
    "# may want to change this depending on reimplementation of\n",
    "# lem_stop function above\n",
    "min_count = 1\n",
    "\n",
    "# terms that occur within this window of text are associated with it\n",
    "# during the training of the model. if the corpus of text contains large\n",
    "# sentences then it may be a good idea to change this to something larger.\n",
    "# the documentation suggests 10 as an upper bound and 4-7 as a good range.\n",
    "window = 4\n",
    "\n",
    "# skip-gram technique: boolean that determines skipgram vs continuous bag of words\n",
    "# model. the default is 1, skipgram\n",
    "sg = 1\n",
    "\n",
    "prr2vec = Word2Vec(\n",
    "    [prr2vec_data],\n",
    "    sg=sg,\n",
    "    size=size,\n",
    "    min_count=min_count,\n",
    "    window=window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sincerely', 0.9992898106575012),\n",
       " ('act', 0.9992607235908508),\n",
       " ('category', 0.9992291331291199),\n",
       " ('which', 0.9991952180862427),\n",
       " ('each', 0.9991693496704102),\n",
       " (\"'s\", 0.9991583228111267),\n",
       " ('khandelwal@kingcounty', 0.9991531372070312),\n",
       " ('boise', 0.9991462230682373),\n",
       " ('be', 0.9991364479064941),\n",
       " ('in', 0.9991249442100525)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prr2vec.wv['zone']\n",
    "#prr2vec.wv.most_similar('state')\n",
    "#prr2vec.wv.vocab\n",
    "\n",
    "\n",
    "#prr2vec_data = [ lem_stop(i) for i in docs ]\n",
    "# the output here is a list of all of the processed, filtered text\n",
    "#\n",
    "# this is wrapped in a list in order to help word2vec work with the word embeddings\n",
    "# rather than just the characters of the text. normally word2vec takes sentences\n",
    "# rather than just words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/spacy/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TSNE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-0d4094271860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtsne_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprr2vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-129-6af7c76e2364>\u001b[0m in \u001b[0;36mtsne_plot\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtsne_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pca'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TSNE' is not defined"
     ]
    }
   ],
   "source": [
    "tsne_plot(prr2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ONCE we have vectors\n",
    "#step 3 - build model\n",
    "#3 main tasks that vectors help with\n",
    "#DISTANCE, SIMILARITY, RANKING\n",
    "\n",
    "# Dimensionality of the resulting word vectors.\n",
    "#more dimensions, more computationally expensive to train\n",
    "#but also more accurate\n",
    "#more dimensions = more generalized\n",
    "num_features = 300\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 3\n",
    "\n",
    "# Context window length.\n",
    "context_size = 7\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "#0 - 1e-5 is good for this\n",
    "downsampling = 1e-3\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "#random number generator\n",
    "#deterministic, good for debugging\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "prr2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=2,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot sort vocabulary after model weights already initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-9c81d02e7eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprr2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/envs/spacy/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         report_values = self.vocabulary.prepare_vocab(\n\u001b[1;32m    483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             trim_rule=trim_rule, **kwargs)\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'memory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_retained_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/spacy/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mprepare_vocab\u001b[0;34m(self, hs, negative, wv, update, keep_raw_vocab, trim_rule, min_count, sample, dry_run)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_vocab\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;31m# add info about each word's Huffman encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/spacy/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36msort_vocab\u001b[0;34m(self, wv)\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0;34m\"\"\"Sort the vocabulary so the most frequent words have the lowest indexes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot sort vocabulary after model weights already initialized.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot sort vocabulary after model weights already initialized."
     ]
    }
   ],
   "source": [
    "prr2vec.build_vocab(docs.text)\n",
    "\n",
    "token_count = sum([len(doc) for doc in docs.text])\n",
    "print(\"The corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must specify an explict epochs count. The usual value is epochs=model.epochs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-214-58043653cd44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprr2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprr2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprr2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/envs/spacy/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/spacy/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/spacy/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             total_words=total_words, **kwargs)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/spacy/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[0;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m             )\n\u001b[1;32m    618\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You must specify an explict epochs count. The usual value is epochs=model.epochs.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m         logger.info(\n\u001b[1;32m    621\u001b[0m             \u001b[0;34m\"training model with %i workers on %i vocabulary and %i features, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You must specify an explict epochs count. The usual value is epochs=model.epochs."
     ]
    }
   ],
   "source": [
    "prr2vec.train(docs.text, total_examples=prr2vec.corpus_count, epochs=prr2vec.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['requesting',\n",
       " 'copies',\n",
       " 'of',\n",
       " 'hsd',\n",
       " \"'s\",\n",
       " 'service',\n",
       " 'agreements',\n",
       " 'with',\n",
       " 'compass',\n",
       " 'housing',\n",
       " 'alliance',\n",
       " 'and',\n",
       " 'solid',\n",
       " 'ground',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'correspondence',\n",
       " 'emails',\n",
       " 'and',\n",
       " 'other',\n",
       " 'documents',\n",
       " 'that',\n",
       " 'reference',\n",
       " 'beatrice',\n",
       " 'holbert',\n",
       " 'carolyn',\n",
       " 'kinniebrow',\n",
       " 'or',\n",
       " 'carolyn',\n",
       " 'bilal',\n",
       " 'reports',\n",
       " 'regarding',\n",
       " 'financial',\n",
       " 'reviews',\n",
       " 'of',\n",
       " 'share',\n",
       " 'in',\n",
       " '2009',\n",
       " '2011',\n",
       " 'and',\n",
       " '2013from',\n",
       " 'september',\n",
       " '2010',\n",
       " 'all',\n",
       " 'email',\n",
       " 'correspondence',\n",
       " 'from',\n",
       " 'anyone',\n",
       " 'at',\n",
       " 'hsd',\n",
       " 'that',\n",
       " 'include',\n",
       " 'any',\n",
       " 'of',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'below',\n",
       " 'peggy',\n",
       " 'hotesscott',\n",
       " 'morrow',\n",
       " 'nate',\n",
       " 'martin',\n",
       " 'share',\n",
       " 'wheel',\n",
       " 'seattle',\n",
       " 'housing',\n",
       " 'and',\n",
       " 'resource',\n",
       " 'effort\"marvin',\n",
       " 'futrell\"low',\n",
       " 'income',\n",
       " 'housing',\n",
       " 'institute\"\"michelle',\n",
       " 'marchand\"\"steven',\n",
       " 'isaacson\"\"lantz',\n",
       " 'rowland',\n",
       " 'jarvis',\n",
       " 'capucion',\n",
       " 'nickelsville\"\"sharon',\n",
       " 'lee\"\"tent',\n",
       " 'city\"(1',\n",
       " 'documents',\n",
       " 'and',\n",
       " 'communications',\n",
       " 'that',\n",
       " 'will',\n",
       " 'help',\n",
       " 'me',\n",
       " 'to',\n",
       " 'ascertain',\n",
       " 'how',\n",
       " 'many',\n",
       " 'other',\n",
       " 'individuals',\n",
       " 'may',\n",
       " 'be',\n",
       " 'experiencing',\n",
       " 'problems',\n",
       " 'enrolling',\n",
       " 'in',\n",
       " 'the',\n",
       " 'the',\n",
       " 'udp',\n",
       " 'program(2',\n",
       " 'relevant',\n",
       " 'copies',\n",
       " 'of',\n",
       " 'any',\n",
       " 'documents',\n",
       " 'communications',\n",
       " 'and',\n",
       " 'procedure',\n",
       " 'manuals',\n",
       " 'that',\n",
       " 'set',\n",
       " 'forth',\n",
       " 'the',\n",
       " 'procedure',\n",
       " 'for',\n",
       " 'enrolling',\n",
       " 'applicants',\n",
       " 'in',\n",
       " 'the',\n",
       " 'utility',\n",
       " 'discount',\n",
       " 'program',\n",
       " 'including',\n",
       " 'the',\n",
       " 'application',\n",
       " 'process',\n",
       " 'itself(3',\n",
       " 'all',\n",
       " 'documents',\n",
       " 'and',\n",
       " 'communications',\n",
       " 'that',\n",
       " 'relate',\n",
       " 'to',\n",
       " 'the',\n",
       " 'erroneous',\n",
       " 'statement',\n",
       " 'of',\n",
       " 'my',\n",
       " 'current',\n",
       " 'rent',\n",
       " 'in',\n",
       " 'my',\n",
       " 'application',\n",
       " 'the',\n",
       " 'application',\n",
       " 'states',\n",
       " 'it',\n",
       " 'is',\n",
       " '295.00',\n",
       " 'month',\n",
       " 'when',\n",
       " 'clearly',\n",
       " 'told',\n",
       " 'seattle',\n",
       " 'city',\n",
       " 'light',\n",
       " 'that',\n",
       " 'pay',\n",
       " '395.00',\n",
       " 'in',\n",
       " 'monthly',\n",
       " 'rent(4',\n",
       " 'all',\n",
       " 'documents',\n",
       " 'and',\n",
       " 'communications',\n",
       " 'to',\n",
       " 'and',\n",
       " 'from',\n",
       " 'sha',\n",
       " 're',\n",
       " 'eligibility',\n",
       " 'of',\n",
       " 'sha',\n",
       " 'tenants',\n",
       " 'or',\n",
       " 'housing',\n",
       " 'choice',\n",
       " 'voucher',\n",
       " 'holders',\n",
       " 'for',\n",
       " 'the',\n",
       " 'udpre',\n",
       " 'public',\n",
       " 'records',\n",
       " 'request',\n",
       " 'magnolia',\n",
       " 'bridge',\n",
       " 'holland',\n",
       " 'nathan',\n",
       " 'christopher',\n",
       " 'sex',\n",
       " 'offender',\n",
       " 'registration',\n",
       " '8017dear',\n",
       " 'wa',\n",
       " 'dept',\n",
       " 'of',\n",
       " 'ecology',\n",
       " 'king',\n",
       " 'county',\n",
       " 'sex',\n",
       " 'offender',\n",
       " 'unit',\n",
       " 'seattle',\n",
       " 'police',\n",
       " 'dept',\n",
       " 'sex',\n",
       " 'offender',\n",
       " 'detail',\n",
       " 'mayor',\n",
       " 'murray',\n",
       " 'council',\n",
       " 'seattle',\n",
       " 'human',\n",
       " 'services',\n",
       " 'dept',\n",
       " 'and',\n",
       " 'seattle',\n",
       " 'transportation',\n",
       " 'dept.:nathan',\n",
       " 'christopher',\n",
       " 'holland',\n",
       " 'nate',\n",
       " 'holland',\n",
       " 'from',\n",
       " 'california',\n",
       " 'who',\n",
       " 'is',\n",
       " 'convicted',\n",
       " 'child',\n",
       " 'molester',\n",
       " 'felon',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'whole',\n",
       " 'other',\n",
       " 'litany',\n",
       " 'of',\n",
       " 'crimes',\n",
       " 'that',\n",
       " 'spd',\n",
       " 'forgot',\n",
       " 'to',\n",
       " 'mention',\n",
       " 'was',\n",
       " 'on',\n",
       " 'washington',\n",
       " 's',\n",
       " 'most',\n",
       " 'wanted',\n",
       " 'sex',\n",
       " 'offender',\n",
       " 'hiding',\n",
       " 'out',\n",
       " 'in',\n",
       " 'the',\n",
       " 'jungle',\n",
       " 'and',\n",
       " 'now',\n",
       " 'as',\n",
       " 'of',\n",
       " 'today',\n",
       " 'friday',\n",
       " 'october',\n",
       " '2016',\n",
       " 'is',\n",
       " 'registered',\n",
       " 'as',\n",
       " 'transient',\n",
       " 'with',\n",
       " 'the',\n",
       " 'king',\n",
       " 'county',\n",
       " 'sheriff',\n",
       " 's',\n",
       " 'office',\n",
       " 'as',\n",
       " 'residing',\n",
       " 'at',\n",
       " '1600',\n",
       " 'west',\n",
       " 'garfield',\n",
       " 'street',\n",
       " 'he',\n",
       " 'is',\n",
       " 'living',\n",
       " 'under',\n",
       " 'on',\n",
       " 'the',\n",
       " 'city',\n",
       " 'of',\n",
       " 'seattle',\n",
       " 'department',\n",
       " 'of',\n",
       " 'transportation',\n",
       " 's',\n",
       " 'magnolia',\n",
       " 'bridge',\n",
       " 'pier',\n",
       " 'ramp',\n",
       " 'and',\n",
       " 'dumping',\n",
       " 'his',\n",
       " 'personal',\n",
       " 'human',\n",
       " 'waste',\n",
       " 'into',\n",
       " 'the',\n",
       " 'adjacent',\n",
       " 'waters',\n",
       " 'of',\n",
       " 'puget',\n",
       " 'sound',\n",
       " 'and',\n",
       " 'nearby',\n",
       " 'the',\n",
       " 'elliott',\n",
       " 'bay',\n",
       " 'bike',\n",
       " 'trail',\n",
       " 'seriously',\n",
       " 'how',\n",
       " 'can',\n",
       " 'anyone',\n",
       " 'be',\n",
       " 'allowed',\n",
       " 'to',\n",
       " 'live',\n",
       " 'under',\n",
       " 'the',\n",
       " 'city',\n",
       " 'of',\n",
       " 'seattle',\n",
       " 's',\n",
       " 'structurally',\n",
       " 'deficient',\n",
       " 'magnolia',\n",
       " 'bridge',\n",
       " 'that',\n",
       " 'is',\n",
       " 'crumbling',\n",
       " 'deteriorated',\n",
       " 'and',\n",
       " 'has',\n",
       " 'loose',\n",
       " 'chunks',\n",
       " 'of',\n",
       " 'concrete',\n",
       " 'falling',\n",
       " 'below',\n",
       " 'that',\n",
       " 'could',\n",
       " 'kill',\n",
       " 'this',\n",
       " 'person',\n",
       " 'http://www.kiro7.com/news/bridge/246321877',\n",
       " 'specifically',\n",
       " 'who',\n",
       " 'from',\n",
       " 'the',\n",
       " 'city',\n",
       " 'of',\n",
       " 'seattle',\n",
       " 'by',\n",
       " 'name',\n",
       " 'title',\n",
       " 'department',\n",
       " 'and',\n",
       " 'by',\n",
       " 'written',\n",
       " 'authorization',\n",
       " 'consented',\n",
       " 'to',\n",
       " 'this',\n",
       " 'person',\n",
       " 'being',\n",
       " 'able',\n",
       " 'to',\n",
       " 'reside',\n",
       " 'and/or',\n",
       " 'register',\n",
       " 'at',\n",
       " '1600',\n",
       " 'west',\n",
       " 'garfield',\n",
       " 'street',\n",
       " 'and',\n",
       " 'more',\n",
       " 'specifically',\n",
       " 'is',\n",
       " 'allowing',\n",
       " 'this',\n",
       " 'person',\n",
       " 'to',\n",
       " 'dump',\n",
       " 'his',\n",
       " 'human',\n",
       " 'waste',\n",
       " 'into',\n",
       " 'the',\n",
       " 'waters',\n",
       " 'of',\n",
       " 'puget',\n",
       " 'sound',\n",
       " '',\n",
       " 'per',\n",
       " 'the',\n",
       " 'washington',\n",
       " 'public',\n",
       " 'records',\n",
       " 'request',\n",
       " 'act',\n",
       " 'please',\n",
       " 'provide',\n",
       " 'me',\n",
       " 'with',\n",
       " 'copies',\n",
       " 'by',\n",
       " 'email',\n",
       " 'of',\n",
       " 'any',\n",
       " 'and',\n",
       " 'all',\n",
       " 'correspondence',\n",
       " 'policy',\n",
       " 'permit',\n",
       " 'document',\n",
       " 'authorization',\n",
       " 'consent',\n",
       " 'land',\n",
       " 'use',\n",
       " 'permit',\n",
       " 'sepa',\n",
       " 'checklist',\n",
       " 'sepa',\n",
       " 'determination',\n",
       " 'npdes',\n",
       " 'permit',\n",
       " 'sewage',\n",
       " 'spill',\n",
       " 'dumping',\n",
       " 'reports',\n",
       " 'and',\n",
       " 'any',\n",
       " 'other',\n",
       " 'documents',\n",
       " 'related',\n",
       " 'hereto',\n",
       " 'for',\n",
       " 'this',\n",
       " 'person',\n",
       " 'and',\n",
       " 'this',\n",
       " 'location',\n",
       " 'unsuitable',\n",
       " 'unsafe',\n",
       " 'unacceptable',\n",
       " 'but',\n",
       " 'hey',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'there',\n",
       " 'could',\n",
       " 'possibly',\n",
       " 'be',\n",
       " 'cash',\n",
       " 'reward',\n",
       " 'out',\n",
       " 'there',\n",
       " 'on',\n",
       " 'this',\n",
       " 'person',\n",
       " 'as',\n",
       " 'well',\n",
       " 'maybe',\n",
       " 'the',\n",
       " 'city',\n",
       " 'can',\n",
       " 'claim',\n",
       " 'it',\n",
       " 'to',\n",
       " 'apply',\n",
       " 'towards',\n",
       " 'the',\n",
       " 'hazmat',\n",
       " 'cleanup',\n",
       " 'costs',\n",
       " 'sincerely',\n",
       " 'concerned',\n",
       " 'jane',\n",
       " 'doegrubstello@mac.com-a',\n",
       " 'copy',\n",
       " 'of',\n",
       " 'the',\n",
       " 'expenses',\n",
       " 'for',\n",
       " 'the',\n",
       " 'pronto',\n",
       " 'bike',\n",
       " 'share',\n",
       " 'program',\n",
       " 'for',\n",
       " '2016',\n",
       " 'along',\n",
       " 'with',\n",
       " 'the',\n",
       " 'income',\n",
       " 'statement',\n",
       " 'for',\n",
       " 'the',\n",
       " 'same',\n",
       " 'period',\n",
       " '2016',\n",
       " 'through',\n",
       " '2016',\n",
       " '-a',\n",
       " 'copy',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'expenses',\n",
       " 'related',\n",
       " 'to',\n",
       " 'the',\n",
       " '50',\n",
       " 'million',\n",
       " 'dollars',\n",
       " 'budgeted',\n",
       " 'for',\n",
       " 'the',\n",
       " 'homeless',\n",
       " 'programs',\n",
       " 'from',\n",
       " '20the',\n",
       " 'most',\n",
       " 'recent',\n",
       " 'job',\n",
       " 'description',\n",
       " 'for',\n",
       " 'efren',\n",
       " 'agmata',\n",
       " 'most',\n",
       " 'recent',\n",
       " 'job',\n",
       " 'descriptions',\n",
       " 'for',\n",
       " 'two',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'supervisors',\n",
       " 'above',\n",
       " 'mr.',\n",
       " 'agmata',\n",
       " 'along',\n",
       " 'with',\n",
       " 'name',\n",
       " 'and',\n",
       " 'contact',\n",
       " 'info',\n",
       " 'for',\n",
       " 'each',\n",
       " 'catherine',\n",
       " 'lester',\n",
       " 's',\n",
       " 'calendar',\n",
       " 'for',\n",
       " 'june',\n",
       " '2016',\n",
       " 'through',\n",
       " 'december',\n",
       " 'of',\n",
       " '2016i',\n",
       " 'would',\n",
       " 'like',\n",
       " 'all',\n",
       " 'the',\n",
       " 'dates',\n",
       " 'of',\n",
       " 'site',\n",
       " 'visits',\n",
       " 'conducted',\n",
       " 'by',\n",
       " 'the',\n",
       " 'city',\n",
       " 'to',\n",
       " 'nickelsville',\n",
       " 'for',\n",
       " '2014',\n",
       " 'and',\n",
       " 'who',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'site',\n",
       " 'for',\n",
       " 'each',\n",
       " 'date',\n",
       " 'please',\n",
       " 'address',\n",
       " 'each',\n",
       " 'item',\n",
       " 'as',\n",
       " 'separate',\n",
       " 'request',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'receive',\n",
       " 'things',\n",
       " 'as',\n",
       " 'they',\n",
       " 'are',\n",
       " 'discovered',\n",
       " 'by',\n",
       " 'the',\n",
       " 'person',\n",
       " 'in',\n",
       " 'charge',\n",
       " 'of',\n",
       " 'finding',\n",
       " 'these',\n",
       " 'records',\n",
       " 'the',\n",
       " '2016',\n",
       " 'city',\n",
       " 'contract',\n",
       " 'with',\n",
       " 'share',\n",
       " 'states',\n",
       " 'that',\n",
       " 'if',\n",
       " 'reports',\n",
       " 'are',\n",
       " 'not',\n",
       " 'received',\n",
       " 'in',\n",
       " 'timely',\n",
       " 'manner',\n",
       " 'or',\n",
       " 'not',\n",
       " 'completed',\n",
       " 'invoices',\n",
       " 'will',\n",
       " 'be',\n",
       " 'held',\n",
       " 'for',\n",
       " 'payment',\n",
       " '....',\n",
       " 'does',\n",
       " 'share',\n",
       " 'have',\n",
       " 'any',\n",
       " 'invoices',\n",
       " 'being',\n",
       " 'held',\n",
       " 'currently',\n",
       " 'if',\n",
       " 'how',\n",
       " 'many',\n",
       " 'what',\n",
       " 'for',\n",
       " 'for',\n",
       " 'each',\n",
       " 'and',\n",
       " 'for',\n",
       " 'what',\n",
       " 'monetary',\n",
       " 'amount',\n",
       " 'for',\n",
       " 'each)?2',\n",
       " 'the',\n",
       " 'contract',\n",
       " 'also',\n",
       " 'states',\n",
       " 'that',\n",
       " 'the',\n",
       " 'agency',\n",
       " 'shall',\n",
       " 'maintain',\n",
       " 'client',\n",
       " 'grievance',\n",
       " 'procedures',\n",
       " '...',\n",
       " 'documentation',\n",
       " 'of',\n",
       " 'all',\n",
       " 'grievances',\n",
       " 'filed',\n",
       " 'against',\n",
       " 'the',\n",
       " 'program',\n",
       " '....',\n",
       " '\"i',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'receive',\n",
       " 'any',\n",
       " 'and',\n",
       " 'all',\n",
       " 'of',\n",
       " 'these',\n",
       " 'grievances',\n",
       " 'filed',\n",
       " 'against',\n",
       " 'share',\n",
       " 'from',\n",
       " '2013',\n",
       " 'to',\n",
       " 'present',\n",
       " 'is',\n",
       " 'mary',\n",
       " 'flowers',\n",
       " 'the',\n",
       " 'sole',\n",
       " 'overseer',\n",
       " 'of',\n",
       " 'the',\n",
       " 'reporting',\n",
       " 'documents',\n",
       " 'share',\n",
       " 'is',\n",
       " 'supposed',\n",
       " 'to',\n",
       " 'supply?requesting',\n",
       " 'all',\n",
       " 'reports',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'the',\n",
       " 'financial',\n",
       " 'reviews',\n",
       " 'of',\n",
       " 'the',\n",
       " 'agency',\n",
       " 'known',\n",
       " 'as',\n",
       " 'share',\n",
       " 'for',\n",
       " '2009',\n",
       " '2011',\n",
       " 'and',\n",
       " '2013please',\n",
       " 'see',\n",
       " 'attached',\n",
       " 'please',\n",
       " 'see',\n",
       " 'attached',\n",
       " 'please',\n",
       " 'see',\n",
       " 'attached',\n",
       " 'records',\n",
       " 'requested',\n",
       " 'are',\n",
       " 'email',\n",
       " 'sent',\n",
       " 'to',\n",
       " 'or',\n",
       " 'from',\n",
       " 'catherine',\n",
       " 'lester',\n",
       " 'terry',\n",
       " 'mclellan',\n",
       " 'gloria',\n",
       " 'hatcher',\n",
       " 'mays',\n",
       " 'and/or',\n",
       " 'tiffany',\n",
       " 'washington',\n",
       " 'that',\n",
       " 'contain',\n",
       " 'specific',\n",
       " 'verbiage:1',\n",
       " 'yell',\n",
       " 'yells',\n",
       " 'yelled',\n",
       " 'yelling2',\n",
       " 'scream',\n",
       " 'screams',\n",
       " 'screamed',\n",
       " 'screaming3',\n",
       " 'conflict4',\n",
       " 'fight',\n",
       " 'fought',\n",
       " 'complain',\n",
       " 'complained',\n",
       " 'complaining6',\n",
       " 'argue',\n",
       " 'argues',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'intimidate',\n",
       " 'intimidated',\n",
       " 'intimidating8.)\"workplace',\n",
       " 'expectations\"9',\n",
       " 'open',\n",
       " 'communication\"10.)\"performing',\n",
       " 'all',\n",
       " 'duties',\n",
       " 'productively\"11',\n",
       " 'probationary',\n",
       " 'discharge',\n",
       " 'discrimination',\n",
       " 'discriminates',\n",
       " 'discriminated',\n",
       " 'discriminating',\n",
       " 'hi',\n",
       " \"-i'm\",\n",
       " 'looking',\n",
       " 'for',\n",
       " 'monthly',\n",
       " 'report',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'generated',\n",
       " 'by',\n",
       " 'hsd',\n",
       " 'on',\n",
       " 'the',\n",
       " 'homeless',\n",
       " 'state',\n",
       " 'of',\n",
       " 'emergency',\n",
       " 'are',\n",
       " 'you',\n",
       " 'able',\n",
       " 'to',\n",
       " 'forward',\n",
       " 'me',\n",
       " 'each',\n",
       " 'copy',\n",
       " 'of',\n",
       " 'this',\n",
       " 'report',\n",
       " 'going',\n",
       " 'back',\n",
       " '12',\n",
       " 'months',\n",
       " 'if',\n",
       " 'collecting',\n",
       " 'all',\n",
       " 'the',\n",
       " 'copies',\n",
       " 'would',\n",
       " 'cause',\n",
       " 'delay',\n",
       " 'would',\n",
       " 'appreciate',\n",
       " 'receiving',\n",
       " 'the',\n",
       " 'most',\n",
       " 'recent',\n",
       " 'report',\n",
       " 'first',\n",
       " 'thank',\n",
       " 'you!any',\n",
       " 'and',\n",
       " 'all',\n",
       " 'monthly',\n",
       " 'quarterly',\n",
       " 'and',\n",
       " 'annual',\n",
       " 'director',\n",
       " \"'s\",\n",
       " 'reports',\n",
       " 'issued',\n",
       " 'by',\n",
       " 'the',\n",
       " 'director',\n",
       " 'of',\n",
       " 'the',\n",
       " 'human',\n",
       " 'services',\n",
       " 'department',\n",
       " 'to',\n",
       " 'the',\n",
       " 'mayor',\n",
       " 'or',\n",
       " 'any',\n",
       " 'city',\n",
       " 'council',\n",
       " 'member',\n",
       " 'from',\n",
       " 'january',\n",
       " '2016',\n",
       " 'to',\n",
       " 'january',\n",
       " '2017.1',\n",
       " 'complete',\n",
       " 'copy',\n",
       " 'of',\n",
       " 'my',\n",
       " 'personnel',\n",
       " 'file',\n",
       " 'and',\n",
       " 'any',\n",
       " 'supervisor',\n",
       " 'files',\n",
       " 'for',\n",
       " 'me2',\n",
       " 'copies',\n",
       " 'of',\n",
       " 'any',\n",
       " 'and',\n",
       " 'all',\n",
       " 'email',\n",
       " 'or',\n",
       " 'written',\n",
       " 'exchanges',\n",
       " 'between',\n",
       " 'my',\n",
       " 'supervisor',\n",
       " 'management',\n",
       " 'hr',\n",
       " 'and',\n",
       " 'employees',\n",
       " 'utilized',\n",
       " 'discussing',\n",
       " 'my',\n",
       " 'behavior',\n",
       " 'performance',\n",
       " 'and',\n",
       " 'possible',\n",
       " 'discipline3',\n",
       " 'copy',\n",
       " 'of',\n",
       " 'any',\n",
       " 'records',\n",
       " 'documentation',\n",
       " 'or',\n",
       " 'notes',\n",
       " 'for',\n",
       " 'any',\n",
       " 'investigation',\n",
       " 'related',\n",
       " 'to',\n",
       " 'my',\n",
       " 'performance',\n",
       " 'or',\n",
       " 'behavior',\n",
       " 'in',\n",
       " 'the',\n",
       " 'work',\n",
       " 'placeany',\n",
       " 'communications',\n",
       " 'correspondence',\n",
       " 'statements',\n",
       " 'opinion',\n",
       " 'letters',\n",
       " 'analyses',\n",
       " 'planning',\n",
       " 'or',\n",
       " 'permitting',\n",
       " 'documents',\n",
       " 'relating',\n",
       " 'to',\n",
       " 'the',\n",
       " 'proposed',\n",
       " 'low',\n",
       " 'income',\n",
       " 'homeless',\n",
       " 'encampment',\n",
       " 'in',\n",
       " 'the',\n",
       " 'aurora',\n",
       " 'licton',\n",
       " 'springs',\n",
       " 'urban',\n",
       " 'village',\n",
       " 'according',\n",
       " 'to',\n",
       " 'council',\n",
       " 'bill',\n",
       " 'number',\n",
       " '118310',\n",
       " 'ordinance',\n",
       " 'number',\n",
       " '124747',\n",
       " 'there',\n",
       " 'should',\n",
       " 'be',\n",
       " 'an',\n",
       " 'annual',\n",
       " 'report',\n",
       " 'filed',\n",
       " 'regarding',\n",
       " 'the',\n",
       " 'sanctioned',\n",
       " 'encampments',\n",
       " 'in',\n",
       " 'seattle',\n",
       " 'am',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define some parameters  \n",
    "noisy_pos_tags = ['PROP']\n",
    "min_token_length = 2\n",
    "\n",
    "#Function to check if the token is a noise or not  \n",
    "def isNoise(token):     \n",
    "    is_noise = False\n",
    "    if token.pos_ in noisy_pos_tags:\n",
    "        is_noise = True \n",
    "    elif token.is_stop == True:\n",
    "        is_noise = True\n",
    "    elif len(token.string) <= min_token_length:\n",
    "        is_noise = True\n",
    "    return is_noise \n",
    "\n",
    "def cleanup(token, lower = True):\n",
    "    if lower:\n",
    "       token = token.lower()\n",
    "    return token.strip()\n",
    "\n",
    "cleaned_list = [cleanup(word.string) for word in docs if not isNoise(word)]\n",
    "cleaned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str x in lambda to ensure that everything is processable by spacy\n",
    "#civ['proc'] = civ['request_summary'].apply(lambda x: nlp(str(x)))\n",
    "#listy = civ.proc.tolist()\n",
    "s = ''\n",
    "for row in civ['request_summary']:\n",
    "    s += str(row)\n",
    "    \n",
    "doc = nlp(s)\n",
    "tokenizer = Tokenizer(doc.vocab)\n",
    "\n",
    "#for sentence in enumerate(text.sents):\n",
    "#    print(sentence)\n",
    "#    print('')\n",
    "\n",
    "words = [token.lemma_ for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "\n",
    "# noun tokens that arent stop words or punctuations\n",
    "nouns = [token.lemma_ for token in doc if token.is_stop != True and token.is_punct != True and token.pos_ == \"NOUN\"]\n",
    "\n",
    "# five most common tokens\n",
    "word_freq = Counter(words)\n",
    "common_words = word_freq.most_common(5)\n",
    "\n",
    "# five most common noun tokens\n",
    "noun_freq = Counter(nouns)\n",
    "common_nouns = noun_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-fd8c5def41f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m for doc in nlp.pipe(civ['request_summary'].astype('unicode').values, batch_size=50,\n\u001b[0;32m----> 6\u001b[0;31m                         n_threads=3):\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/spacy/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, texts, as_tuples, n_threads, batch_size, disable, cleanup)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0moriginal_strings_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mnr_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/spacy/lib/python3.6/site-packages/cytoolz/itertoolz.pyx\u001b[0m in \u001b[0;36mcytoolz.itertoolz.partition_all.__next__ (cytoolz/itertoolz.c:14538)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.parse_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.get_batch_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.precompute_hiddens.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/spacy/lib/python3.6/site-packages/spacy/_ml.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         Yf = self.ops.xp.dot(X,\n\u001b[0;32m--> 149\u001b[0;31m             self.W.reshape((self.nF*self.nO*self.nP, self.nI)).T)\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mYf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mYf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "lemma = []\n",
    "pos = []\n",
    "\n",
    "for doc in nlp.pipe(civ['request_summary'].astype('unicode').values, batch_size=50,\n",
    "                        n_threads=3):\n",
    "    if doc.is_parsed:\n",
    "        tokens.append([n.text for n in doc])\n",
    "        lemma.append([n.lemma_ for n in doc])\n",
    "        pos.append([n.pos_ for n in doc])\n",
    "    else:\n",
    "        # We want to make sure that the lists of parsed results have the\n",
    "        # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n",
    "        tokens.append(None)\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "\n",
    "civ['tokens'] = tokens\n",
    "civ['lemma'] = lemma\n",
    "civ['pos'] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideas for analysis\n",
    "is it possible to predict the department that a request goes to, given the body of a request?\n",
    "https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49\n",
    "\n",
    "is it possible to do LDA or topic modeling, to gauge what people are typically writing about in PRRs?\n",
    "\n",
    "is it possible to discover the frequency of a keyword over time, and plot it?\n",
    "\n",
    "it it possible to collect n-grams, and uncover phrases of relevance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
